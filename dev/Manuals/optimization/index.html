<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization · TransportMaps.jl</title><meta name="title" content="Optimization · TransportMaps.jl"/><meta property="og:title" content="Optimization · TransportMaps.jl"/><meta property="twitter:title" content="Optimization · TransportMaps.jl"/><meta name="description" content="Documentation for TransportMaps.jl."/><meta property="og:description" content="Documentation for TransportMaps.jl."/><meta property="twitter:description" content="Documentation for TransportMaps.jl."/><meta property="og:url" content="https://lukasfritsch.github.io/TransportMaps.jl/Manuals/optimization/"/><meta property="twitter:url" content="https://lukasfritsch.github.io/TransportMaps.jl/Manuals/optimization/"/><link rel="canonical" href="https://lukasfritsch.github.io/TransportMaps.jl/Manuals/optimization/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TransportMaps.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manuals</span><ul><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../hermite_basis/">Basis Functions</a></li><li><a class="tocitem" href="../sparse_map/">Map Parameterization</a></li><li><a class="tocitem" href="../quadrature/">Quadrature Methods</a></li><li class="is-active"><a class="tocitem" href>Optimization</a><ul class="internal"><li><a class="tocitem" href="#Map-from-density"><span>Map-from-density</span></a></li><li><a class="tocitem" href="#Map-from-samples"><span>Map-from-samples</span></a></li></ul></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../Examples/banana_example/">Banana: Map from Density</a></li><li><a class="tocitem" href="../../Examples/mapfromsamples_example/">Banana: Map from Samples</a></li><li><a class="tocitem" href="../../Examples/bod_example/">BOD Parameter Estimation</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manuals</a></li><li class="is-active"><a href>Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/lukasfritsch/TransportMaps.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/lukasfritsch/TransportMaps.jl/blob/main/docs/literate/optimization.jl#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-of-the-Map-Coefficients"><a class="docs-heading-anchor" href="#Optimization-of-the-Map-Coefficients">Optimization of the Map Coefficients</a><a id="Optimization-of-the-Map-Coefficients-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-of-the-Map-Coefficients" title="Permalink"></a></h1><p>A crucial step in constructing transport maps is the optimization of the map coefficients, which determine how well the map represents the target distribution. This process can be approached in two distinct ways, depending on the available information about the target distribution [<a href="../../references/#marzouk2016">1</a>].</p><h2 id="Map-from-density"><a class="docs-heading-anchor" href="#Map-from-density">Map-from-density</a><a id="Map-from-density-1"></a><a class="docs-heading-anchor-permalink" href="#Map-from-density" title="Permalink"></a></h2><p>One way to construct a transport map is to directly optimize its parameters based on the (unnormalized) target density, as shown in <a href="../../Examples/banana_example/#Banana:-Map-from-Density">Banana: Map from Density</a>. This approach requires access to the target density function and uses quadrature schemes to approximate integrals, as introduced in <a href="../quadrature/#Quadrature-Methods">Quadrature Methods</a>.</p><p>Formally, we define the following optimization problem to determine the coefficients <span>$\boldsymbol{a}$</span> of the parameterized map <span>$T$</span>:</p><p class="math-container">\[\min_{\boldsymbol{a}} \sum_{i=1}^{N} w_{q,i}\Big[-\log\pi\bigl(T(\boldsymbol{a},\boldsymbol{z}_{q,i})\bigr)-\log |\det\nabla T(\boldsymbol{a},\boldsymbol{z}_{q,i}) |\Big]\]</p><p>As noted by [<a href="../../references/#marzouk2016">1</a>], this optimization problem is generally non-convex. Specifically, it is only convex when the target density <span>$\pi(\boldsymbol{x})$</span> is log-concave. Especially in Bayesian inference, where the target density represents the posterior density, the function is not log-concave, resulting in a non-convex optimization problem.</p><p>In this package, map optimization is performed with the help of <a href="https://julianlsolvers.github.io/Optim.jl/stable/"><code>Optim.jl</code></a>, and support a wide range of optimizers and options (such as convergence criteria and printing preferences). Specifically, we can pass our <code>optimize!</code> function the desired <code>optimizer</code> and <code>options</code>. For a full overview of available options, see the <a href="https://julianlsolvers.github.io/Optim.jl/stable/user/config/">Optim.jl configuration documentation</a>.</p><p>To perform the optimization of the map coefficients, we call:</p><pre><code class="language-julia hljs">optimize!(M::PolynomialMap, target_density::Function, quadrature::AbstractQuadratureWeights;
  optimizer::Optim.AbstractOptimizer = LBFGS(), options::Optim.Options = Optim.Options())</code></pre><p>We have to provide the polynomial map <code>M</code>, the target density function, and a quadrature scheme. Optionally, we can specify the optimizer (default is <code>LBFGS()</code>) and options.</p><div class="admonition is-info" id="Set-initial-coefficients-9d506371392d507d"><header class="admonition-header">Set initial coefficients<a class="admonition-anchor" href="#Set-initial-coefficients-9d506371392d507d" title="Permalink"></a></header><div class="admonition-body"><p>As the starting point of the optimization, the map coefficients can be set using <code>setcoefficients!(M, coeffs)</code>, where <code>coeffs</code> is a vector of coefficients.</p></div></div><h3 id="Usage"><a class="docs-heading-anchor" href="#Usage">Usage</a><a id="Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Usage" title="Permalink"></a></h3><p>First we load the packages:</p><pre><code class="language-julia hljs">using TransportMaps
using Optim
using Distributions
using Plots</code></pre><p>Then, define the target density and quadrature scheme. Here, we use the same banana-shaped density as in <a href="../../Examples/banana_example/#Banana:-Map-from-Density">Banana: Map from Density</a>:</p><pre><code class="language-julia hljs">banana_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)
target = MapTargetDensity(banana_density, :auto_diff)
quadrature = GaussHermiteWeights(10, 2)</code></pre><p>Set optimization options to print the trace every 20 iterations:</p><pre><code class="language-julia hljs">opts_trace = Optim.Options(iterations = 200, show_trace = true, show_every = 20, store_trace = true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">                x_abstol = 0.0
                x_reltol = 0.0
                f_abstol = 0.0
                f_reltol = 0.0
                g_abstol = 1.0e-8
          outer_x_abstol = 0.0
          outer_x_reltol = 0.0
          outer_f_abstol = 0.0
          outer_f_reltol = 0.0
          outer_g_abstol = 1.0e-8
           f_calls_limit = 0
           g_calls_limit = 0
           h_calls_limit = 0
       allow_f_increases = true
 allow_outer_f_increases = true
        successive_f_tol = 1
              iterations = 200
        outer_iterations = 1000
             store_trace = true
           trace_simplex = false
              show_trace = true
          extended_trace = false
           show_warnings = true
              show_every = 20
                callback = nothing
              time_limit = NaN
</code></pre><p>We will try the following optimizers from <code>Optim.jl</code>, ordered from simplest to most sophisticated:</p><h3 id="Gradient-Descent"><a class="docs-heading-anchor" href="#Gradient-Descent">Gradient Descent</a><a id="Gradient-Descent-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-Descent" title="Permalink"></a></h3><p>The most basic optimization algorithm, Gradient Descent iteratively moves in the direction of the negative gradient. It is simple and robust, but can be slow to converge, especially for ill-conditioned problems.</p><pre><code class="language-julia hljs">M_gd = PolynomialMap(2, 2)
res_gd = optimize!(M_gd, target, quadrature; optimizer = GradientDescent(), options = opts_trace)
println(res_gd)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Iter     Function value   Gradient norm
     0     3.397270e+00     4.787106e-01
 * time: 5.1021575927734375e-5
    20     2.850583e+00     4.636259e-02
 * time: 1.8712990283966064
    40     2.843777e+00     1.929781e-02
 * time: 3.110964059829712
    60     2.841951e+00     1.418934e-02
 * time: 4.376067161560059
    80     2.840976e+00     1.062491e-02
 * time: 5.6427271366119385
   100     2.840432e+00     8.037175e-03
 * time: 6.906660079956055
   120     2.840124e+00     6.146411e-03
 * time: 8.170628070831299
   140     2.839946e+00     4.739998e-03
 * time: 9.441350221633911
   160     2.839841e+00     3.677012e-03
 * time: 10.704704999923706
   180     2.839779e+00     2.864831e-03
 * time: 11.972302198410034
   200     2.839741e+00     2.239348e-03
 * time: 13.240100145339966
 * Status: failure (reached maximum number of iterations)

 * Candidate solution
    Final objective value:     2.839741e+00

 * Found with
    Algorithm:     Gradient Descent

 * Convergence measures
    |x - x&#39;|               = 5.18e-04 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 2.13e-04 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.47e-06 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 5.17e-07 ≰ 0.0e+00
    |g(x)|                 = 2.24e-03 ≰ 1.0e-08

 * Work counters
    Seconds run:   13  (vs limit Inf)
    Iterations:    200
    f(x) calls:    500
    ∇f(x) calls:   500</code></pre><h3 id="Conjugate-Gradient"><a class="docs-heading-anchor" href="#Conjugate-Gradient">Conjugate Gradient</a><a id="Conjugate-Gradient-1"></a><a class="docs-heading-anchor-permalink" href="#Conjugate-Gradient" title="Permalink"></a></h3><p>Conjugate Gradient improves upon basic gradient descent by using conjugate directions, which can accelerate convergence for large-scale or quadratic problems. It requires gradient information but not the Hessian.</p><pre><code class="language-julia hljs">M_cg = PolynomialMap(2, 2)
res_cg = optimize!(M_cg, target, quadrature; optimizer = ConjugateGradient(), options = opts_trace)
println(res_cg)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Iter     Function value   Gradient norm
     0     3.397270e+00     4.787106e-01
 * time: 0.0001609325408935547
    20     2.839683e+00     4.660320e-04
 * time: 0.8487870693206787
    40     2.839682e+00     2.358450e-07
 * time: 2.3610870838165283
 * Status: success

 * Candidate solution
    Final objective value:     2.839682e+00

 * Found with
    Algorithm:     Conjugate Gradient

 * Convergence measures
    |x - x&#39;|               = 1.03e-08 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 4.18e-09 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 6.00e-12 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 2.11e-12 ≰ 0.0e+00
    |g(x)|                 = 7.88e-09 ≤ 1.0e-08

 * Work counters
    Seconds run:   3  (vs limit Inf)
    Iterations:    47
    f(x) calls:    140
    ∇f(x) calls:   107</code></pre><h3 id="Nelder-Mead"><a class="docs-heading-anchor" href="#Nelder-Mead">Nelder-Mead</a><a id="Nelder-Mead-1"></a><a class="docs-heading-anchor-permalink" href="#Nelder-Mead" title="Permalink"></a></h3><p>Nelder-Mead is a derivative-free optimizer that uses a simplex of points to search for the minimum. It is useful when gradients are unavailable or unreliable, but may be less efficient for high-dimensional or smooth problems.</p><pre><code class="language-julia hljs">M_nm = PolynomialMap(2, 2)
res_nm = optimize!(M_nm, target, quadrature; optimizer = NelderMead(), options = opts_trace)
println(res_nm)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Iter     Function value    √(Σ(yᵢ-ȳ)²)/n
------   --------------    --------------
     0     3.385576e+00     6.605357e-03
 * time: 6.29425048828125e-5
    20     3.325067e+00     1.181961e-02
 * time: 0.15948700904846191
    40     3.217121e+00     1.767829e-02
 * time: 0.30322790145874023
    60     3.145469e+00     4.181386e-03
 * time: 0.42649102210998535
    80     3.117130e+00     5.447396e-03
 * time: 0.5439980030059814
   100     3.093404e+00     3.317695e-03
 * time: 0.6495950222015381
   120     3.069923e+00     3.715479e-03
 * time: 0.7482380867004395
   140     3.051873e+00     3.572733e-03
 * time: 0.8661050796508789
   160     3.038170e+00     3.071201e-03
 * time: 0.981774091720581
   180     3.021624e+00     2.623475e-03
 * time: 1.0914371013641357
   200     3.003035e+00     3.663402e-03
 * time: 1.2070250511169434
 * Status: failure (reached maximum number of iterations)

 * Candidate solution
    Final objective value:     3.001466e+00

 * Found with
    Algorithm:     Nelder-Mead

 * Convergence measures
    √(Σ(yᵢ-ȳ)²)/n ≰ 1.0e-08

 * Work counters
    Seconds run:   1  (vs limit Inf)
    Iterations:    200
    f(x) calls:    306</code></pre><h3 id="BFGS"><a class="docs-heading-anchor" href="#BFGS">BFGS</a><a id="BFGS-1"></a><a class="docs-heading-anchor-permalink" href="#BFGS" title="Permalink"></a></h3><p>BFGS is a quasi-Newton method that builds up an approximation to the Hessian matrix using gradient evaluations. It is generally faster and more robust than gradient descent and conjugate gradient for smooth problems.</p><pre><code class="language-julia hljs">M_bfgs = PolynomialMap(2, 2)
res_bfgs = optimize!(M_bfgs, target, quadrature; optimizer = BFGS(), options = opts_trace)
println(res_bfgs)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Iter     Function value   Gradient norm
     0     3.397270e+00     4.787106e-01
 * time: 7.510185241699219e-5
 * Status: success

 * Candidate solution
    Final objective value:     2.839682e+00

 * Found with
    Algorithm:     BFGS

 * Convergence measures
    |x - x&#39;|               = 9.04e-07 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 3.66e-07 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 2.58e-10 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 9.07e-11 ≰ 0.0e+00
    |g(x)|                 = 2.87e-09 ≤ 1.0e-08

 * Work counters
    Seconds run:   1  (vs limit Inf)
    Iterations:    11
    f(x) calls:    30
    ∇f(x) calls:   30</code></pre><h3 id="LBFGS"><a class="docs-heading-anchor" href="#LBFGS">LBFGS</a><a id="LBFGS-1"></a><a class="docs-heading-anchor-permalink" href="#LBFGS" title="Permalink"></a></h3><p>LBFGS is a limited-memory version of BFGS, making it suitable for large-scale problems where storing the full Hessian approximation is impractical. It is the default optimizer in many scientific computing packages due to its efficiency and reliability.</p><pre><code class="language-julia hljs">M_lbfgs = PolynomialMap(2, 2)
res_lbfgs = optimize!(M_lbfgs, target, quadrature; optimizer = LBFGS(), options = opts_trace)
println(res_lbfgs)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Iter     Function value   Gradient norm
     0     3.397270e+00     4.787106e-01
 * time: 5.1021575927734375e-5
 * Status: success

 * Candidate solution
    Final objective value:     2.839682e+00

 * Found with
    Algorithm:     L-BFGS

 * Convergence measures
    |x - x&#39;|               = 8.68e-06 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 3.51e-06 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 8.67e-11 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 3.05e-11 ≰ 0.0e+00
    |g(x)|                 = 8.12e-09 ≤ 1.0e-08

 * Work counters
    Seconds run:   1  (vs limit Inf)
    Iterations:    11
    f(x) calls:    32
    ∇f(x) calls:   32</code></pre><p>Finally, we can compare the results by means of variance diagnostic:</p><pre><code class="language-julia hljs">samples_z = randn(1000, 2)
v_gd = variance_diagnostic(M_gd, target, samples_z)
v_cg = variance_diagnostic(M_cg, target, samples_z)
v_nm = variance_diagnostic(M_nm, target, samples_z)
v_bfgs = variance_diagnostic(M_bfgs, target, samples_z)
v_lbfgs = variance_diagnostic(M_lbfgs, target, samples_z)

println(&quot;Variance diagnostic GradientDescent:   &quot;, v_gd)
println(&quot;Variance diagnostic ConjugateGradient: &quot;, v_cg)
println(&quot;Variance diagnostic NelderMead:        &quot;, v_nm)
println(&quot;Variance diagnostic BFGS:              &quot;, v_bfgs)
println(&quot;Variance diagnostic LBFGS:             &quot;, v_lbfgs)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Variance diagnostic GradientDescent:   0.0017488487267375533
Variance diagnostic ConjugateGradient: 0.0017873820689744437
Variance diagnostic NelderMead:        0.08591514550491204
Variance diagnostic BFGS:              0.001787382049819872
Variance diagnostic LBFGS:             0.0017873820154559585</code></pre><p>We can visualize the convergence of all optimizers:</p><pre><code class="language-julia hljs">plot([res_gd.trace[i].iteration for i in 1:length(res_gd.trace)], lw=2,
     [res_gd.trace[i].g_norm for i in 1:length(res_gd.trace)], label=&quot;GradientDescent&quot;)
plot!([res_cg.trace[i].iteration for i in 1:length(res_cg.trace)], lw=2,
     [res_cg.trace[i].g_norm for i in 1:length(res_cg.trace)], label=&quot;ConjugateGradient&quot;)
plot!([res_nm.trace[i].iteration for i in 1:length(res_nm.trace)], lw=2,
     [res_nm.trace[i].g_norm for i in 1:length(res_nm.trace)], label=&quot;NelderMead&quot;)
plot!([res_bfgs.trace[i].iteration for i in 1:length(res_bfgs.trace)], lw=2,
     [res_bfgs.trace[i].g_norm for i in 1:length(res_bfgs.trace)], label=&quot;BFGS&quot;)
plot!([res_lbfgs.trace[i].iteration for i in 1:length(res_lbfgs.trace)], lw=2,
     [res_lbfgs.trace[i].g_norm for i in 1:length(res_lbfgs.trace)], label=&quot;LBFGS&quot;)
plot!(xaxis=:log, yaxis=:log, xlabel=&quot;Iteration&quot;, ylabel=&quot;Gradient norm&quot;,
    title=&quot;Convergence of different optimizers&quot;, xlims=(1, 200),
    legend=:bottomleft)</code></pre><p><img src="../optimization-conv.svg" alt="Optimization Convergence"/></p><p>It becomes clear, that LBFGS and BFGS are the most efficient optimizers in this case, while Nelder-Mead struggles to keep up.</p><h2 id="Map-from-samples"><a class="docs-heading-anchor" href="#Map-from-samples">Map-from-samples</a><a id="Map-from-samples-1"></a><a class="docs-heading-anchor-permalink" href="#Map-from-samples" title="Permalink"></a></h2><p>Another strategy of constructing a transport map is to use samples of the target density, as seen in <a href="../../Examples/mapfromsamples_example/#Banana:-Map-from-Samples">Banana: Map from Samples</a>. The formulation of transport map estimation in this way has the benefit to transform the problem into a convex optimization problem, when reference density is log-concave [<a href="../../references/#marzouk2016">1</a>]. Since we can choose the reference density, we can leverage this property to simplify the optimization process.</p><p>When the map is constructed from samples, the optimization problem is formulated by minimizing the Kullback-Leibler divergence between the pushforward of the reference density and the empirical distribution of the samples. We denote the transport map by <span>$S$</span>, which pushes forward the target distribution to the reference distribution. This leads to the following optimization problem:</p><p class="math-container">\[\min_{\boldsymbol{a}} -\frac{1}{M} \sum_{i=1}^{M} \log \rho\left(S(\boldsymbol{a}, \boldsymbol{x}_i)\right) - \log \left|\det \nabla S(\boldsymbol{a}, \boldsymbol{x}_i)\right|\]</p><p>where <span>$\{\boldsymbol{x}_i\}_{i=1}^M$</span> are samples from the target distribution, and <span>$\rho(\cdot)$</span> is the density of the reference distribution.</p><p>To perform the optimization, we can use the same <code>optimize!</code> function as before, but now we pass samples instead of a target density and quadrature scheme. Similarly, we can specify the optimizer and options:</p><pre><code class="language-julia hljs">optimize!(M::PolynomialMap, samples::AbstractArray{&lt;:Real};
  optimizer::Optim.AbstractOptimizer = LBFGS(), options::Optim.Options = Optim.Options())</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../quadrature/">« Quadrature Methods</a><a class="docs-footer-nextpage" href="../../Examples/banana_example/">Banana: Map from Density »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Monday 15 September 2025 07:10">Monday 15 September 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
