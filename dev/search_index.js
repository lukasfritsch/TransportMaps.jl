var documenterSearchIndex = {"docs":
[{"location":"Manuals/quadrature_methods/#Quadrature-Methods","page":"Quadrature Methods","title":"Quadrature Methods","text":"","category":"section"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"A crucial part of transport-map applications is selecting a suitable quadrature method. Quadrature is used in map optimization, in particular when evaluating the Kullback–Leibler divergence","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"mathcalD_mathrmKLleft(T_ rho  piright)=int Biglog rho(boldsymbolz)-log pi(T(boldsymbola boldsymbolz))-log operatornamedet nabla T(boldsymbola boldsymbolz) Big rho(boldsymbolz)  mathrmd boldsymbolz","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"Here, boldsymbolz denotes the variable in the reference space with density rho(boldsymbolz), pi(boldsymbolx) is the target density, and T(boldsymbola boldsymbolz) is the transport map parameterized by boldsymbola.","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"In practice we approximate the integral by a quadrature sum:","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"sum_i=1^N w_qiBig-logpibigl(T(boldsymbolaboldsymbolz_qi)bigr)-log detnabla T(boldsymbolaboldsymbolz_qi) Big","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"The quadrature points boldsymbolz_qi and weights w_qi must be chosen so the sum approximates expectations with respect to the reference measure rho(boldsymbolz), which is typically the standard Gaussian.","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"Especially in Bayesian inference, where evaluating the target density pi(boldsymbolx) can be expensive, using efficient quadrature methods is important to reduce the number of target evaluations [4].","category":"page"},{"location":"Manuals/quadrature_methods/#Monte-Carlo","page":"Quadrature Methods","title":"Monte Carlo","text":"","category":"section"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"Monte Carlo estimates an expectation Ef(Z) by sampling Z_i sim mathcalN(0 mathbfI) and forming the sample average. It is simple and robust; weights are uniform. Convergence is stochastic (O(n^-12)) but independent of dimension.","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"We start by loading the necessary packages:","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"using TransportMaps\nusing Plots\n\nusing Random # hide\nRandom.seed!(42) # hide\nmc = MonteCarloWeights(500, 2)\np_mc = scatter(mc.points[:, 1], mc.points[:, 2], ms=3,\n    label=\"MC samples\", title=\"Monte Carlo (500 pts)\", aspect_ratio=1)\nsavefig(\"quadrature_mc.svg\"); nothing # hide","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"(Image: Monte Carlo samples)","category":"page"},{"location":"Manuals/quadrature_methods/#Latin-Hypercube-Sampling-(LHS)","page":"Quadrature Methods","title":"Latin Hypercube Sampling (LHS)","text":"","category":"section"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"Latin Hypercube is a stratified sampling design that improves space-filling over plain Monte Carlo; weights remain uniform. It often reduces variance for low to moderate dimensions.","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"lhs = LatinHypercubeWeights(500, 2)\np_lhs = scatter(lhs.points[:, 1], lhs.points[:, 2], ms=3,\n    label=\"LHS samples\", title=\"Latin Hypercube (500 pts)\", aspect_ratio=1)\nsavefig(\"quadrature_lhs.svg\"); nothing # hide","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"(Image: Latin Hypercube samples)","category":"page"},{"location":"Manuals/quadrature_methods/#Tensor-product-Gauss–Hermite","page":"Quadrature Methods","title":"Tensor-product Gauss–Hermite","text":"","category":"section"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"Gauss–Hermite quadrature provides nodes boldsymbolz_q i and weights w_q i such that for smooth integrands the integral with respect to the Gaussian density is approximated very accurately. Tensor-product rules take the 1D rule in each coordinate and form all combinations, producing N=n^d nodes for n points per dimension.","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"hermite = GaussHermiteWeights(5, 2)\np_hermite = scatter(hermite.points[:, 1], hermite.points[:, 2],\n    ms=4, label=\"Gauss–Hermite\", title=\"Tensor Gauss–Hermite (5 × 5)\", aspect_ratio=1)\nsavefig(\"quadrature_hermite.svg\"); nothing # hide","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"(Image: Gauss-Hermite tensor product sample)","category":"page"},{"location":"Manuals/quadrature_methods/#Sparse-Smolyak-Gauss–Hermite","page":"Quadrature Methods","title":"Sparse Smolyak Gauss–Hermite","text":"","category":"section"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"Sparse Smolyak grids combine 1D quadrature rules across dimensions with carefully chosen coefficients to cancel redundant high-order interactions. The result is substantially fewer nodes than the full tensor product while retaining high accuracy for mixed smooth functions. Note that Smolyak quadrature can produce negative weights; this is expected for higher-order correction terms.","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"sparse = SparseSmolyakWeights(2, 2)\np_sparse = scatter(sparse.points[:, 1], sparse.points[:, 2], ms=6,\n    label=\"Smolyak\", title=\"Sparse Smolyak (level 2)\", aspect_ratio=1)\nsavefig(\"quadrature_smolyak.svg\"); nothing # hide","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"(Image: Sparse Smolyak sample)","category":"page"},{"location":"Manuals/quadrature_methods/#Quick-usage-notes","page":"Quadrature Methods","title":"Quick usage notes","text":"","category":"section"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"Use Monte Carlo or LHS for high-dimensional problems where deterministic quadrature is infeasible.\nUse tensor Gauss–Hermite in very low dimensions when the integrand is smooth and high accuracy is required.\nUse Sparse Smolyak for intermediate dimensions (e.g. d leq 6) to get higher accuracy at much lower cost than the full tensor rule.","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"","category":"page"},{"location":"Manuals/quadrature_methods/","page":"Quadrature Methods","title":"Quadrature Methods","text":"This page was generated using Literate.jl.","category":"page"},{"location":"references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"Y. Marzouk, T. Moselhy, M. Parno and A. Spantini. Sampling via Measure Transport: An Introduction. In: Handbook of Uncertainty Quantification, edited by R. Ghanem, D. Higdon and H. Owhadi (Springer International Publishing, Cham, 2016); pp. 1–41.\n\n\n\nM. Ramgraber, D. Sharp, M. L. Provost and Y. Marzouk. A Friendly Introduction to Triangular Transport (Mar 2025), arXiv:2503.21673 [stat].\n\n\n\nR. Baptista, Y. Marzouk and O. Zahm. On the Representation and Learning of Monotone Triangular Transport Maps. Foundations of Computational Mathematics (2023).\n\n\n\nJ. Grashorn, M. Broggi, L. Chamoin and M. Beer. Efficiency Comparison of MCMC and Transport Map Bayesian Posterior Estimation for Structural Health Monitoring. Mechanical Systems and Signal Processing 216, 111440 (2024).\n\n\n\nM. Rosenblatt. Remarks on a multivariate transformation. The annals of mathematical statistics 23, 470–472 (1952).\n\n\n\nH. Knothe. Contributions to the theory of convex bodies. The Michigan Mathematical Journal 4, 39–52 (1957).\n\n\n\nM. Parno, P.-B. Rubio, D. Sharp, M. Brennan, R. Baptista, H. Bonart and Y. Marzouk. MParT: Monotone Parameterization Toolkit. Journal of Open Source Software 7, 4843 (2022).\n\n\n\nB. Zanger, O. Zahm, T. Cui and M. Schreiber. Sequential Transport Maps Using SoS Density Estimation and alpha``-Divergences (Oct 2024), arXiv:2402.17943 [stat].\n\n\n\nB. Sudret. Global Sensitivity Analysis Using Polynomial Chaos Expansions. Reliability Engineering & System Safety 93, 964–979 (2008).\n\n\n\nD. Xiu and G. E. Karniadakis. The Wiener–Askey Polynomial Chaos for Stochastic Differential Equations. SIAM Journal on Scientific Computing 24, 619–644 (2002).\n\n\n\nN. Lüthen, S. Marelli and B. Sudret. Sparse Polynomial Chaos Expansions: Literature Survey and Benchmark. SIAM/ASA Journal on Uncertainty Quantification 9, 593–649 (2021).\n\n\n\nA. B. Sullivan, D. M. Snyder and S. A. Rounds. Controls on biochemical oxygen demand in the upper Klamath River, Oregon. Chemical Geology 269, 12–21 (2010).\n\n\n\n","category":"page"},{"location":"Manuals/optimization/#Optimization-of-the-Map-Coefficients","page":"Optimization","title":"Optimization of the Map Coefficients","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"A crucial step in constructing transport maps is the optimization of the map coefficients, which determine how well the map represents the target distribution. This process can be approached in two distinct ways, depending on the available information about the target distribution [1].","category":"page"},{"location":"Manuals/optimization/#Map-from-density","page":"Optimization","title":"Map-from-density","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"One way to construct a transport map is to directly optimize its parameters based on the (unnormalized) target density, as shown in Banana: Map from Density. This approach requires access to the target density function and uses quadrature schemes to approximate integrals, as introduced in Quadrature Methods.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"Formally, we define the following optimization problem to determine the coefficients boldsymbola of the parameterized map T:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"min_boldsymbola sum_i=1^N w_qiBig-logpibigl(T(boldsymbolaboldsymbolz_qi)bigr)-log detnabla T(boldsymbolaboldsymbolz_qi) Big","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"As noted by [1], this optimization problem is generally non-convex. Specifically, it is only convex when the target density pi(boldsymbolx) is log-concave. Especially in Bayesian inference, where the target density represents the posterior density, the function is not log-concave, resulting in a non-convex optimization problem.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"In this package, map optimization is performed with the help of Optim.jl, and support a wide range of optimizers and options (such as convergence criteria and printing preferences). Specifically, we can pass our optimize! function the desired optimizer and options. For a full overview of available options, see the Optim.jl configuration documentation.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"To perform the optimization of the map coefficients, we call:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"optimize!(M::PolynomialMap, target_density::Function, quadrature::AbstractQuadratureWeights;\n  optimizer::Optim.AbstractOptimizer = LBFGS(), options::Optim.Options = Optim.Options())","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"We have to provide the polynomial map M, the target density function, and a quadrature scheme. Optionally, we can specify the optimizer (default is LBFGS()) and options.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"note: Set initial coefficients\nAs the starting point of the optimization, the map coefficients can be set using setcoefficients!(M, coeffs), where coeffs is a vector of coefficients.","category":"page"},{"location":"Manuals/optimization/#Usage","page":"Optimization","title":"Usage","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"First we load the packages:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"using TransportMaps\nusing Optim\nusing Distributions\nusing Plots","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"Then, define the target density and quadrature scheme. Here, we use the same banana-shaped density as in Banana: Map from Density:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"banana_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)\ntarget = MapTargetDensity(banana_density, :auto_diff)\nquadrature = GaussHermiteWeights(10, 2)\nnothing #hide","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"Set optimization options to print the trace every 20 iterations:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"opts_trace = Optim.Options(iterations=200, show_trace=true, show_every=20, store_trace=true)","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"We will try the following optimizers from Optim.jl, ordered from simplest to most sophisticated:","category":"page"},{"location":"Manuals/optimization/#Gradient-Descent","page":"Optimization","title":"Gradient Descent","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"The most basic optimization algorithm, Gradient Descent iteratively moves in the direction of the negative gradient. It is simple and robust, but can be slow to converge, especially for ill-conditioned problems.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"M_gd = PolynomialMap(2, 2)\nres_gd = optimize!(M_gd, target, quadrature; optimizer=GradientDescent(), options=opts_trace)\nprintln(res_gd)","category":"page"},{"location":"Manuals/optimization/#Conjugate-Gradient","page":"Optimization","title":"Conjugate Gradient","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"Conjugate Gradient improves upon basic gradient descent by using conjugate directions, which can accelerate convergence for large-scale or quadratic problems. It requires gradient information but not the Hessian.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"M_cg = PolynomialMap(2, 2)\nres_cg = optimize!(M_cg, target, quadrature; optimizer=ConjugateGradient(), options=opts_trace)\nprintln(res_cg)","category":"page"},{"location":"Manuals/optimization/#Nelder-Mead","page":"Optimization","title":"Nelder-Mead","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"Nelder-Mead is a derivative-free optimizer that uses a simplex of points to search for the minimum. It is useful when gradients are unavailable or unreliable, but may be less efficient for high-dimensional or smooth problems.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"M_nm = PolynomialMap(2, 2)\nres_nm = optimize!(M_nm, target, quadrature; optimizer=NelderMead(), options=opts_trace)\nprintln(res_nm)","category":"page"},{"location":"Manuals/optimization/#BFGS","page":"Optimization","title":"BFGS","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"BFGS is a quasi-Newton method that builds up an approximation to the Hessian matrix using gradient evaluations. It is generally faster and more robust than gradient descent and conjugate gradient for smooth problems.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"M_bfgs = PolynomialMap(2, 2)\nres_bfgs = optimize!(M_bfgs, target, quadrature; optimizer=BFGS(), options=opts_trace)\nprintln(res_bfgs)","category":"page"},{"location":"Manuals/optimization/#LBFGS","page":"Optimization","title":"LBFGS","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"LBFGS is a limited-memory version of BFGS, making it suitable for large-scale problems where storing the full Hessian approximation is impractical. It is the default optimizer in many scientific computing packages due to its efficiency and reliability.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"M_lbfgs = PolynomialMap(2, 2)\nres_lbfgs = optimize!(M_lbfgs, target, quadrature; optimizer=LBFGS(), options=opts_trace)\nprintln(res_lbfgs)","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"Finally, we can compare the results by means of variance diagnostic:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"samples_z = randn(1000, 2)\nv_gd = variance_diagnostic(M_gd, target, samples_z)\nv_cg = variance_diagnostic(M_cg, target, samples_z)\nv_nm = variance_diagnostic(M_nm, target, samples_z)\nv_bfgs = variance_diagnostic(M_bfgs, target, samples_z)\nv_lbfgs = variance_diagnostic(M_lbfgs, target, samples_z)\n\nprintln(\"Variance diagnostic GradientDescent:   \", v_gd)\nprintln(\"Variance diagnostic ConjugateGradient: \", v_cg)\nprintln(\"Variance diagnostic NelderMead:        \", v_nm)\nprintln(\"Variance diagnostic BFGS:              \", v_bfgs)\nprintln(\"Variance diagnostic LBFGS:             \", v_lbfgs)","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"We can visualize the convergence of all optimizers:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"plot([res_gd.trace[i].iteration for i in 1:length(res_gd.trace)], lw=2,\n    [res_gd.trace[i].g_norm for i in 1:length(res_gd.trace)], label=\"GradientDescent\")\nplot!([res_cg.trace[i].iteration for i in 1:length(res_cg.trace)], lw=2,\n    [res_cg.trace[i].g_norm for i in 1:length(res_cg.trace)], label=\"ConjugateGradient\")\nplot!([res_nm.trace[i].iteration for i in 1:length(res_nm.trace)], lw=2,\n    [res_nm.trace[i].g_norm for i in 1:length(res_nm.trace)], label=\"NelderMead\")\nplot!([res_bfgs.trace[i].iteration for i in 1:length(res_bfgs.trace)], lw=2,\n    [res_bfgs.trace[i].g_norm for i in 1:length(res_bfgs.trace)], label=\"BFGS\")\nplot!([res_lbfgs.trace[i].iteration for i in 1:length(res_lbfgs.trace)], lw=2,\n    [res_lbfgs.trace[i].g_norm for i in 1:length(res_lbfgs.trace)], label=\"LBFGS\")\nplot!(xaxis=:log, yaxis=:log, xlabel=\"Iteration\", ylabel=\"Gradient norm\",\n    title=\"Convergence of different optimizers\", xlims=(1, 200),\n    legend=:bottomleft)\nsavefig(\"optimization-conv.svg\"); nothing # hide","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"(Image: Optimization Convergence)","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"It becomes clear, that LBFGS and BFGS are the most efficient optimizers in this case, while Nelder-Mead struggles to keep up.","category":"page"},{"location":"Manuals/optimization/#Map-from-samples","page":"Optimization","title":"Map-from-samples","text":"","category":"section"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"Another strategy of constructing a transport map is to use samples of the target density, as seen in Banana: Map from Samples. The formulation of transport map estimation in this way has the benefit to transform the problem into a convex optimization problem, when reference density is log-concave [1]. Since we can choose the reference density, we can leverage this property to simplify the optimization process.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"When the map is constructed from samples, the optimization problem is formulated by minimizing the Kullback-Leibler divergence between the pushforward of the reference density and the empirical distribution of the samples. We denote the transport map by S, which pushes forward the target distribution to the reference distribution. This leads to the following optimization problem:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"min_boldsymbola -frac1M sum_i=1^M log rholeft(S(boldsymbola boldsymbolx_i)right) - log leftdet nabla S(boldsymbola boldsymbolx_i)right","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"where boldsymbolx_i_i=1^M are samples from the target distribution, and rho(cdot) is the density of the reference distribution.","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"To perform the optimization, we can use the same optimize! function as before, but now we pass samples instead of a target density and quadrature scheme. Similarly, we can specify the optimizer and options:","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"optimize!(M::PolynomialMap, samples::AbstractArray{<:Real};\n  optimizer::Optim.AbstractOptimizer = LBFGS(), options::Optim.Options = Optim.Options())","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"","category":"page"},{"location":"Manuals/optimization/","page":"Optimization","title":"Optimization","text":"This page was generated using Literate.jl.","category":"page"},{"location":"Manuals/basis_functions/#Basis-Functions","page":"Basis Functions","title":"Basis Functions","text":"","category":"section"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"In order to construct a parameterized map, we first need to define a suitable basis.","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"This manual describes the different one-dimensional basis families currently implemented in TransportMaps.jl. We focus on variants of the (probabilists') Hermite polynomials and recently proposed edge-controlled versions [3], [2].","category":"page"},{"location":"Manuals/basis_functions/#Probabilistic-Hermite-Basis","page":"Basis Functions","title":"Probabilistic Hermite Basis","text":"","category":"section"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"The probabilistic Hermite polynomials form an orthonormal basis with respect to the standard normal density","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"phi(z) = frac1sqrt2 pi expleft(-fracz^22right)","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"They satisfy the three-term recurrence operatornameHe_n+1(z)=z operatornameHe_n(z)-n operatornameHe_n-1(z)  with (operatornameHe_0(z)=1) and (operatornameHe_1(z)=z).","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"Orthonormal polynomial bases such as the Hermite family are useful for several reasons. Orthogonality with respect to a reference measure makes coefficient estimation stable: projections onto the basis are simple inner products and a truncated series gives the best L^2-approximation under that measure. These properties are the same reasons orthogonal polynomials are used in Polynomial Chaos Expansions (PCE) for surrogate modelling and uncertainty quantification (see Sudret [9] for a concise introduction). In the Gaussian case the Hermite polynomials are the natural choice (Wiener–Askey scheme, see [10]).","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"We want to visualize the Hermite polynomials, first we load the necessary packages:","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"using Distributions\nusing Plots\nusing TransportMaps","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"Then we construct the basis via HermiteBasis() or HermiteBasis(:none) (:none means no edge control):","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"basis = HermiteBasis()\nz = -3:0.01:3\n\np1 = plot(xlabel=\"z\", ylabel=\"Basis function\", title=\"Standard Hermite Basis\")\nfor degree in 0:4\n    plot!(p1, z, map(x -> basisfunction(basis, degree, x), z), label=\"degree $degree\")\nend\nsavefig(\"hermite_basis_standard.svg\"); nothing # hide","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"(Image: Standard Hermite Basis)","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"If we zoom out, we can see that the tails grow quickly for large z:","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"z = -7:0.1:7\n\np2 = plot(xlabel=\"z\", ylabel=\"Basis function\", title=\"Standard Hermite Basis\")\nfor degree in 0:4\n    plot!(p2, z, map(x -> basisfunction(basis, degree, x), z), label=\"degree $degree\")\nend\nsavefig(\"hermite_basis_standard_zoom.svg\"); nothing # hide","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"(Image: Standard Hermite Basis)","category":"page"},{"location":"Manuals/basis_functions/#Linearized-Hermite-Basis","page":"Basis Functions","title":"Linearized Hermite Basis","text":"","category":"section"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"Linearized Hermite polynomials (edge-linearized basis) were introduced in [3] to control growth for large z by replacing the polynomial with a tangent line outside data-dependent bounds z^lz^u:","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"mathcalH^mathrmLin_j(z)=frac1sqrtZ_alpha_j\nbegincases\nmathrmHe_j(z^l)+mathrmHe_j(z^l)(z-z^l)  z z^l \nmathrmHe_j(z)  z^lle z le z^u \nmathrmHe_j(z^u)+mathrmHe_j(z^u)(z-z^u)  z z^u\nendcases","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"The bounds are chosen here as the 0.01 and 0.99 empirical quantiles of (reference) samples. Alternatively, they can be chosen as the quantiles of the respective reference density. The normalization constant Z_alpha_j follows the definition in the paper: Z_alpha_j=alpha_j for jk and Z_alpha_k=(alpha_k+1).","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"basis = LinearizedHermiteBasis(Normal(), 4, 1)\nprintln(\"Linearization bounds: \", basis.linearizationbounds)\n\np3 = plot(xlabel=\"z\", ylabel=\"Basis function\", title=\"Linearized Hermite Basis\")\nfor degree in 0:4\n    plot!(p3, z, map(x -> basisfunction(basis, degree, x), z), label=\"degree $degree\")\nend\nsavefig(\"hermite_basis_linearized.svg\"); nothing # hide","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"(Image: Linearized Hermite Basis)","category":"page"},{"location":"Manuals/basis_functions/#Edge-Controlled-(Weighted)-Hermite-Basis:-Gaussian-Weight","page":"Basis Functions","title":"Edge-Controlled (Weighted) Hermite Basis: Gaussian Weight","text":"","category":"section"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"Edge control modifies each Hermite polynomial with a decaying weight to reduce growth in the tails [2]. Using a Gaussian weight gives:","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"mathcalH_j^textGauss(z)=mathrmHe_j(z)expleft(-tfracz^24right)","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"basis = GaussianWeightedHermiteBasis()\n\np4 = plot(xlabel=\"z\", ylabel=\"Basis function\", title=\"Gaussian-Weighted Hermite Basis\")\nfor degree in 0:4\n    plot!(p4, z, map(x -> basisfunction(basis, degree, x), z), label=\"degree $degree\")\nend\nsavefig(\"hermite_basis_gaussian.svg\"); nothing # hide","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"(Image: Gaussian Weighted Hermite Basis)","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"note: Note\nIn order to preserve some extrapolation properties, the weights are only applied to polynomials of degree j geq 2, as noted in [2].","category":"page"},{"location":"Manuals/basis_functions/#Edge-Controlled-Hermite-Basis:-Cubic-Spline-Weight","page":"Basis Functions","title":"Edge-Controlled Hermite Basis: Cubic Spline Weight","text":"","category":"section"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"A cubic spline weight smoothly damps the polynomials outside a radius r, also introduced in [2]. In this implementation, we define r based on the 0.01 and 0.99 quantile values z^l z^u:","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"mathcalH_j^mathrmCub(z)=operatornameHe_j(z)left(2 u^3-3 u^2+1right)qquad u=minleft(1fraczrright) r=2max(z^lz^u)","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"basis = CubicSplineHermiteBasis(Normal())\n\np5 = plot(xlabel=\"z\", ylabel=\"Basis function\", title=\"Cubic Spline Weighted Hermite Basis\")\nfor degree in 0:4\n    plot!(p5, z, map(x -> basisfunction(basis, degree, x), z), label=\"degree $degree\")\nend\nsavefig(\"hermite_basis_cubic.svg\"); nothing # hide","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"(Image: Cubic Spline Weighted Hermite Basis)","category":"page"},{"location":"Manuals/basis_functions/#Summary","page":"Basis Functions","title":"Summary","text":"","category":"section"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"We showcased four basis variants:","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"Standard (orthonormal) Hermite\nLinearized Hermite (piecewise linear tails)\nGaussian-weighted Hermite (exponential damping)\nCubic-spline-weighted Hermite (compact-style smooth damping)","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"These can be supplied when constructing polynomial transport maps to tune stability, tail behavior, and sparsity characteristics.","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"","category":"page"},{"location":"Manuals/basis_functions/","page":"Basis Functions","title":"Basis Functions","text":"This page was generated using Literate.jl.","category":"page"},{"location":"Examples/banana_adaptive/#Banana:-Adaptive-Transport-Map-from-Samples","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"","category":"section"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"This implements the ATM algorithm from [3] to approximate the banana distribution using an adaptive polynomial transport map.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"As an example, we once again consider the banana distribution defined by the density:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"p(x) = phi(x_1) cdot phi(x_2 - x_1^2)","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"where phi is the standard normal PDF.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"using Random # hide\nRandom.seed!(123) # hide\nnothing # hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"We start with the necessary packages:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"using TransportMaps\nusing Distributions\nusing LinearAlgebra\nusing Plots","category":"page"},{"location":"Examples/banana_adaptive/#Generating-Target-Samples","page":"Banana: Adaptive Transport Map from Samples","title":"Generating Target Samples","text":"","category":"section"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"The generation of samples from the banana distribution is done in the same way as in the example Banana: Map from Samples. Here, we use N = 500 samples for the ATM learning.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"banana_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)\n\nnum_samples = 500\n\nfunction generate_banana_samples(n_samples::Int)\n    samples = Matrix{Float64}(undef, n_samples, 2)\n\n    count = 0\n    while count < n_samples\n        x1 = randn() * 2\n        x2 = randn() * 3 + x1^2\n\n        if rand() < banana_density([x1, x2]) / 0.4\n            count += 1\n            samples[count, :] = [x1, x2]\n        end\n    end\n\n    return samples\nend\nnothing #hide\n\nprintln(\"Generating samples from banana distribution...\")\ntarget_samples = generate_banana_samples(num_samples)\nprintln(\"Generated $(size(target_samples, 1)) samples\")","category":"page"},{"location":"Examples/banana_adaptive/#Creating-the-Transport-Map","page":"Banana: Adaptive Transport Map from Samples","title":"Creating the Transport Map","text":"","category":"section"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"First, create a linear transport map as a starting point. This is also the default behavior of the optimize_adaptive_transportmap function, which standardizes the samples using a linear map based on their marginal mean and standard deviation when no explicit linear map is provided.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"L = LinearMap(target_samples)","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Then, we perform adaptive transport map learning with k-fold cross-validation. We use the setup as in [3]: We select a Hermite basis with linearization, use the modified Softplus rectifier with parameter beta = 2 and k = 5 folds. We set the maximum number of terms to 3 and 6 for the two components, respectively.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Calling the optimize_adaptive_transportmap function performs the adaptive learning of map terms and returns the learned map, optimization results, selected terms, and selected folds. We can provide the initial linear map L to standardize the samples before learning the ATM, and also specify options, such as the rectifier, basis and options for the optimization process. The function returns the ComposedMap of the linear map and the learned adaptive transport map.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"M, results, selected_terms, selected_folds = optimize_adaptive_transportmap(\n    target_samples, [3, 6], 5, L, Softplus(2.))\nnothing # hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"The adaptive map learning prints out information about the learning process, including the selected terms and the training and test objectives for each fold.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"We see, that in the first component, the ATM selected 2 terms (out of the maximum 3), and in the second component, it selected all 5 out of the maximum 6 terms. The number of selected terms is chosen based on the test objective across the folds.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"To visualized which terms were selected, we can plot the multi-index sets of the learned ATM:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"ind_atm = getmultiindexsets(M.polynomialmap[2])\n\ndim = scatter(ind_atm[:, 1], ind_atm[:, 2], ms=30, legend=false)\nplot!(xlims=(-0.5, maximum(ind_atm[:, 1]) + 0.5), ylims=(-0.5, maximum(ind_atm[:, 2]) + 0.5),\n    aspect_ratio=1, xlabel=\"Multi-index α₁\", ylabel=\"Multi-index α₂\")\nxticks!(0:maximum(ind_atm[:, 1]))\nyticks!(0:maximum(ind_atm[:, 2]))\nsavefig(\"atm-indices.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"(Image: Learned Multi-Index) We see that the ATM algorithm selected terms in an L-shape pattern, indicating that lower-order interactions were prioritized.","category":"page"},{"location":"Examples/banana_adaptive/#Testing-the-Map","page":"Banana: Adaptive Transport Map from Samples","title":"Testing the Map","text":"","category":"section"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"new_samples = generate_banana_samples(1000)\nnorm_samples = randn(1000, 2)\nnothing #hide\n\nmapped_banana_samples = inverse(M, norm_samples)\nnothing #hide","category":"page"},{"location":"Examples/banana_adaptive/#Visualizing-Results","page":"Banana: Adaptive Transport Map from Samples","title":"Visualizing Results","text":"","category":"section"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Let's create a scatter plot comparing the original samples with the mapped samples to see how well our transport map learned the distribution:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"p11 = scatter(new_samples[:, 1], new_samples[:, 2],\n    label=\"Original Samples\", alpha=0.5, color=1,\n    title=\"Original Banana Distribution Samples\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\n\nscatter!(p11, mapped_banana_samples[:, 1], mapped_banana_samples[:, 2],\n    label=\"Mapped Samples\", alpha=0.5, color=2,\n    title=\"Transport Map Generated Samples\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\n\nplot(p11, size=(600, 400))\nsavefig(\"atm-comparison-target.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"(Image: Sample Comparison)","category":"page"},{"location":"Examples/banana_adaptive/#Density-Comparison","page":"Banana: Adaptive Transport Map from Samples","title":"Density Comparison","text":"","category":"section"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Similarly, we can compare the true banana density with the learned density obtained via the pullback of the composed map:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"x₁ = range(-3, 3, length=100)\nx₂ = range(-2.5, 4.0, length=100)\n\ntrue_density = [banana_density([x1, x2]) for x2 in x₂, x1 in x₁]\nlearned_density = [pullback(M, [x1, x2]) for x2 in x₂, x1 in x₁]\n\np3 = contour(x₁, x₂, true_density,\n    title=\"True Banana Density\",\n    xlabel=\"x₁\", ylabel=\"x₂\",\n    colormap=:viridis, levels=10)\n\np4 = contour(x₁, x₂, learned_density,\n    title=\"Learned Density (Pullback)\",\n    xlabel=\"x₁\", ylabel=\"x₂\",\n    colormap=:viridis, levels=10)\n\nplot(p3, p4, layout=(1, 2), size=(800, 400))\nsavefig(\"atm-density-comparison.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"(Image: Density Comparison)","category":"page"},{"location":"Examples/banana_adaptive/#Plot-iterations","page":"Banana: Adaptive Transport Map from Samples","title":"Plot iterations","text":"","category":"section"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Additionally, we can visualize the selected terms and optimization objectives over the iterations for the second component of the ATM. First, we retrieve the best fold based on the selected folds during learning:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"map_index = 2  # Choose 2nd component\nbest_fold = selected_folds[map_index]\nres_best = results[map_index][best_fold]\nnothing #hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Then, we can plot the selected terms at each iteration:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"max_1 = maximum(res_best.terms[end][:, 1])\nmax_2 = maximum(res_best.terms[end][:, 2])\n\np = plot(layout=(2, 3), xlims=(-0.5, max_1 + 0.5), ylims=(-0.5, max_2 + 0.5),\n    aspect_ratio=1, xlabel=\"Multi-index α₁\", ylabel=\"Multi-index α₂\", legend=false,)\n\nfor (i, term) in enumerate(res_best.terms)\n    scatter!(p, term[:, 1], term[:, 2], ms=20, title=\"Iteration $i\", subplot=i)\nend\n\nxticks!(0:max_1)\nyticks!(0:max_2)\nplot!(p, size=(800, 600))\nsavefig(\"iterations.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"(Image: Iterations)","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"We can see that in the last iteration, the interaction term (1 1) was added. However, in the end, this term was not selected in the final map based on the cross-validation. To better understand the selection, we can also plot the training and test objectives over the iterations:","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Compare optimization objectives","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"plot(res_best.train_objectives, label=\"Train Objective\", lw=2, ls=:dash, marker=:o)\nplot!(res_best.test_objectives, label=\"Test Objective\", lw=2, ls=:dash, marker=:o)\nplot!(xlabel=\"Iteration\", ylabel=\"Objective Value\",\n    title=\"Training and Test Objectives over Iterations\")\nplot!(size=(600, 400))\nsavefig(\"objectives.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"(Image: Objectives)","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"Here, we see that the test objective increased in the last iteration, indicating overfitting, which is why the last added term was not selected in the final adaptive transport map.","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"","category":"page"},{"location":"Examples/banana_adaptive/","page":"Banana: Adaptive Transport Map from Samples","title":"Banana: Adaptive Transport Map from Samples","text":"This page was generated using Literate.jl.","category":"page"},{"location":"Examples/bod_bayesianinference/#Biochemical-Oxygen-Demand-(BOD)-Example","page":"Bayesian Inference: BOD","title":"Biochemical Oxygen Demand (BOD) Example","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"This example demonstrates Bayesian parameter estimation for a biochemical oxygen demand model using transport maps. The problem comes from environmental engineering and was originally presented in [12] and later used as a benchmark in transport map applications [1].","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"The model describes the evolution of biochemical oxygen demand (BOD) in a river system using an exponential growth model with two uncertain parameters controlling growth and decay rates.","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"using TransportMaps\nusing Plots\nusing Distributions","category":"page"},{"location":"Examples/bod_bayesianinference/#The-Forward-Model","page":"Bayesian Inference: BOD","title":"The Forward Model","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"The BOD model is given by:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"mathcalB(t) = A(1-exp(-Bt))+ varepsilon","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"where the parameters A and B unknown material parameters and varepsilon sim mathcalN(0 10^-3) represents measurement noise.","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"The parameters A and B follow the prior distributions","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"A sim mathcalU(04 12) quad B sim mathcalU(001 031)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"In order to describe the input parameters in an unbounded space, we transform them into a space with standard normal prior distributions p(theta_i) sim mathcalN(0 1). We write A and B as functions of the new variables theta_1 and theta_2 with the help of a density transformation with the standard normal CDF Phi(theta_i):","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"beginaligned\nA = 04 + (12 - 04) cdot Phi(theta_1) \nB = 001 + (031 - 001) cdot Phi(theta_2)\nendaligned","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"We define the forward model as a function of theta and t in Julia:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"function forward_model(t, θ)\n    A = 0.4 + (1.2 - 0.4) * cdf(Normal(), θ[1])\n    B = 0.01 + (0.31 - 0.01) * cdf(Normal(), θ[2])\n    return A * (1 - exp(-B * t))\nend\nnothing #hide","category":"page"},{"location":"Examples/bod_bayesianinference/#Experimental-Data","page":"Bayesian Inference: BOD","title":"Experimental Data","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"We have BOD measurements at five time points:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"t = [1, 2, 3, 4, 5]\nD = [0.18, 0.32, 0.42, 0.49, 0.54]\nσ = sqrt(1e-3)\nnothing #hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Let's visualize the data along with model predictions for different parameter values:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"s = scatter(t, D, label=\"Data\", xlabel=\"Time (t)\", ylabel=\"Biochemical Oxygen Demand (D)\",\n    size=(600, 400), legend=:topleft)\n# Plot model output for some parameter values\nt_values = range(0, 5, length=100)\nfor θ₁ in [-0.5, 0, 0.5]\n    for θ₂ in [-0.5, 0, 0.5]\n        plot!(t_values, [forward_model(ti, [θ₁, θ₂]) for ti in t_values],\n            label=\"(θ₁ = $θ₁, θ₂ = $θ₂)\", linestyle=:dash)\n    end\nend\nsavefig(\"realizations-bod.svg\"); nothing # hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"(Image: BOD Realizations)","category":"page"},{"location":"Examples/bod_bayesianinference/#Bayesian-Inference-Setup","page":"Bayesian Inference: BOD","title":"Bayesian Inference Setup","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"We define the posterior distribution using a standard normal prior on both parameters and a Gaussian likelihood for the observations:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"pi(mathbfyboldsymboltheta) = prod_t=1^5 frac1sqrt2pisigma^2expleft(-frac12sigma^2(y_t - mathcalB(t))^2right)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"function posterior(θ)\n    # Calculate the likelihood\n    likelihood = prod([pdf(Normal(forward_model(t[k], θ), σ), D[k]) for k in 1:5])\n    # Calculate the prior\n    prior = pdf(Normal(), θ[1]) * pdf(Normal(), θ[2])\n    return prior * likelihood\nend\n\ntarget = MapTargetDensity(posterior, :auto_diff)","category":"page"},{"location":"Examples/bod_bayesianinference/#Creating-and-Optimizing-the-Transport-Map","page":"Bayesian Inference: BOD","title":"Creating and Optimizing the Transport Map","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"We use a 2-dimensional polynomial transport map with degree 3 and Softplus rectifier:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"M = PolynomialMap(2, 3, :normal, Softplus(), LinearizedHermiteBasis())","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Set up Gauss-Hermite quadrature for optimization:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"quadrature = GaussHermiteWeights(10, 2)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Optimize the map coefficients:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"res = optimize!(M, target, quadrature)\nprintln(\"Optimization result: \", res)","category":"page"},{"location":"Examples/bod_bayesianinference/#Generating-Posterior-Samples","page":"Bayesian Inference: BOD","title":"Generating Posterior Samples","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Generate samples from the standard normal distribution and map them to the posterior:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"samples_z = randn(1000, 2)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Map the samples through our transport map:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"mapped_samples = evaluate(M, samples_z)","category":"page"},{"location":"Examples/bod_bayesianinference/#Quality-Assessment","page":"Bayesian Inference: BOD","title":"Quality Assessment","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Compute the variance diagnostic to assess the quality of our approximation:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"var_diag = variance_diagnostic(M, target, samples_z)\nprintln(\"Variance Diagnostic: \", var_diag)","category":"page"},{"location":"Examples/bod_bayesianinference/#Visualization","page":"Bayesian Inference: BOD","title":"Visualization","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Plot the mapped samples along with contours of the true posterior density:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"θ₁ = range(-0.5, 1.5, length=100)\nθ₂ = range(-0.5, 3, length=100)\n\nposterior_values = [posterior([θ₁, θ₂]) for θ₂ in θ₂, θ₁ in θ₁]\n\nscatter(mapped_samples[:, 1], mapped_samples[:, 2],\n    label=\"Mapped Samples\", alpha=0.5, color=1,\n    xlabel=\"θ₁\", ylabel=\"θ₂\", title=\"Posterior Density and Mapped Samples\")\ncontour!(θ₁, θ₂, posterior_values, colormap=:viridis, label=\"Posterior Density\")\nsavefig(\"samples-bod.svg\"); nothing # hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"(Image: BOD Samples)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Finally, we can compute the pullback density to visualize how well our transport map approximates the posterior:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"posterior_pullback = [pullback(M, [θ₁, θ₂]) for θ₂ in θ₂, θ₁ in θ₁]\n\ncontour(θ₁, θ₂, posterior_values ./ maximum(posterior_values);\n    levels=5, colormap=:viridis, colorbar=false,\n    label=\"Target\", xlabel=\"θ₁\", ylabel=\"θ₂\")\ncontour!(θ₁, θ₂, posterior_pullback ./ maximum(posterior_pullback);\n    levels=5, colormap=:viridis, linestyle=:dash,\n    label=\"Pullback\")\nsavefig(\"pullback-bod.svg\"); nothing # hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"(Image: BOD Pullback Density)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"We can also visually observe a good agreement between the true posterior and the TM approximation.","category":"page"},{"location":"Examples/bod_bayesianinference/#Conditional-Density-and-Samples","page":"Bayesian Inference: BOD","title":"Conditional Density and Samples","text":"","category":"section"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"We can compute conditional densities and generate conditional samples using the transport map. Therefore, we make use of the factorization of the structure of triangular maps given by the Knothe-Rosenblatt rearrangement [1], [2]:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"pi(mathrmx)=underbracepileft(x_1right)_T_1^-1left(z_1right) underbracepileft(x_2 mid x_1right)_T_2^-1left(z_2  x_1right) underbracepileft(x_3 mid x_1 x_2right)_T_3^-1left(z_3  x_1 x_2right) cdots underbracepileft(x_K mid x_1 ldots x_K-1right)_T_K^-1left(z_K  x_1 ldots x_K-1right)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"This allows us to compute the conditional density pi(theta_2  theta_1) and generate samples from this conditional distribution efficiently. We only need to invert the second component of the map to obtain theta_2 given a fixed value of theta_1 and then push forward samples from the reference distribution.","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"We can use the conditional_sample function to generate samples from the conditional distribution. Therefore, we samples from the standard normal distribution for z_2 and push them through the conditional map. We use the previously generated samples for z_2 and fix theta_1.","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"θ₁ = 0.\nconditional_samples = conditional_sample(M, θ₁, randn(10_000))\nnothing #hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Then, we compute the conditional density of theta_2 given theta_1 first analytically by integrating out theta_1 from the joint posterior. We use numerical integration for this purpose and evaluate the conditional density on a grid.","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"θ_range = 0:0.01:2\nint_analytical = gaussquadrature(ξ -> posterior([θ₁, ξ]), 1000, -10., 10.)\nposterior_conditional(θ₂) = posterior([θ₁, θ₂]) / int_analytical\nconditional_analytical = posterior_conditional.(θ_range)\nnothing #hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Then we compute the conditional density using the transport map, which is given as:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"pi(theta_2  theta_1) = rho_2left(T^2(theta_1 theta_2)^-1right) leftfracpartial T^2(theta_1 theta_2)^-1partial theta_2right","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"conditional_mapped = conditional_density(M, θ_range, θ₁)\nnothing #hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"Finally, we plot the results:","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"histogram(conditional_samples, bins=50, normalize=:pdf, α=0.5,\n    label=\"Conditional Samples\", xlabel=\"θ₂\", ylabel=\"π(θ₂ | θ₁=$θ₁)\")\nplot!(θ_range, conditional_analytical, lw=2, label=\"Analytical Conditional PDF\")\nplot!(θ_range, conditional_mapped, lw=2, label=\"TM Conditional PDF\")\nsavefig(\"conditional-bod.svg\"); nothing # hide","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"(Image: BOD Conditional Density)","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"","category":"page"},{"location":"Examples/bod_bayesianinference/","page":"Bayesian Inference: BOD","title":"Bayesian Inference: BOD","text":"This page was generated using Literate.jl.","category":"page"},{"location":"Examples/banana_mapfromsamples/#Banana:-Map-from-Samples","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"This example demonstrates how to use TransportMaps.jl to approximate a \"banana\" distribution using polynomial transport maps when only samples from the target distribution are available.","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Unlike the density-based approach, this method learns the transport map directly from sample data using optimization techniques. This is particularly useful when the target density is unknown or difficult to evaluate [1].","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"We start with the necessary packages:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"using TransportMaps\nusing Distributions\nusing LinearAlgebra\nusing Plots","category":"page"},{"location":"Examples/banana_mapfromsamples/#Generating-Target-Samples","page":"Banana: Map from Samples","title":"Generating Target Samples","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"The banana distribution has the density:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"p(x) = phi(x_1) cdot phi(x_2 - x_1^2)","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"where phi is the standard normal PDF.","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"banana_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Set up the log-target function for sampling:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"num_samples = 1000\nnothing #hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Generate samples using rejection sampling (no external dependencies)","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"function generate_banana_samples(n_samples::Int)\n    samples = Matrix{Float64}(undef, n_samples, 2)\n\n    count = 0\n    while count < n_samples\n        x1 = randn() * 2\n        x2 = randn() * 3 + x1^2\n\n        if rand() < banana_density([x1, x2]) / 0.4\n            count += 1\n            samples[count, :] = [x1, x2]\n        end\n    end\n\n    return samples\nend\n\nprintln(\"Generating samples from banana distribution...\")\ntarget_samples = generate_banana_samples(num_samples)\nprintln(\"Generated $(size(target_samples, 1)) samples\")","category":"page"},{"location":"Examples/banana_mapfromsamples/#Creating-the-Transport-Map","page":"Banana: Map from Samples","title":"Creating the Transport Map","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"First, we create a linear map to standardize the samples:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"L = LinearMap(target_samples)","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"We create a 2-dimensional polynomial transport map with degree 2. For sample-based optimization, we typically start with lower degrees and can increase complexity as needed.","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"M = PolynomialMap(2, 2, :normal, Softplus())","category":"page"},{"location":"Examples/banana_mapfromsamples/#Optimizing-from-Samples","page":"Banana: Map from Samples","title":"Optimizing from Samples","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"The key difference from density-based optimization is that we optimize directly from the sample data without requiring the density function. Inside the optimization the map is arranged s.t. the \"forward\" direction is from the (unknown) target distribution to the standard normal distribution. Also, we give the linear map to standardize the samples before optimization.","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"res = optimize!(M, target_samples, L)\nnothing # hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"We can check the optimization results of the first component:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"res.optimization_results[1]","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"We can also check the optimization results of the second component:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"res.optimization_results[2]","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Finally, we construct a composed map that combines the linear and polynomial maps:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"C = ComposedMap(L, M)","category":"page"},{"location":"Examples/banana_mapfromsamples/#Testing-the-Map","page":"Banana: Map from Samples","title":"Testing the Map","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Let's generate new samples from the banana density and standard normal samples and map them through our optimized transport map to verify the learned distribution:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"new_samples = generate_banana_samples(1000)\nnorm_samples = randn(1000, 2)\nnothing #hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Map the samples through our transport map. Note that evaluate now transports from reference to target, i.e. mapped_samples should be standard normal samples:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"mapped_samples = evaluate(C, new_samples)\nnothing #hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"while pushing from the standard normal samples to the target distribution generates new samples from the banana distribution:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"mapped_banana_samples = inverse(C, norm_samples)\nnothing #hide","category":"page"},{"location":"Examples/banana_mapfromsamples/#Visualizing-Results","page":"Banana: Map from Samples","title":"Visualizing Results","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Let's create a scatter plot comparing the original samples with the mapped samples to see how well our transport map learned the distribution:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"p11 = scatter(new_samples[:, 1], new_samples[:, 2],\n    label=\"Original Samples\", alpha=0.5, color=1,\n    title=\"Original Banana Distribution Samples\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\n\nscatter!(p11, mapped_banana_samples[:, 1], mapped_banana_samples[:, 2],\n    label=\"Mapped Samples\", alpha=0.5, color=2,\n    title=\"Transport Map Generated Samples\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\n\nplot(p11, size=(600, 400))\nsavefig(\"samples-comparison-target.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"(Image: Sample Comparison)","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"and the resulting samples in standard normal space:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"p12 = scatter(norm_samples[:, 1], norm_samples[:, 2],\n    label=\"Original Samples\", alpha=0.5, color=1,\n    title=\"Original Banana Distribution Samples\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\n\nscatter!(p12, mapped_samples[:, 1], mapped_samples[:, 2],\n    label=\"Mapped Samples\", alpha=0.5, color=2,\n    title=\"Transport Map Generated Samples\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\n\nplot(p12, size=(600, 400), aspect_ratio=1)\nsavefig(\"samples-comparison-reference.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"(Image: Sample Comparison)","category":"page"},{"location":"Examples/banana_mapfromsamples/#Density-Comparison","page":"Banana: Map from Samples","title":"Density Comparison","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"We can also compare the learned density (via pullback) with the true density:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"x₁ = range(-3, 3, length=100)\nx₂ = range(-2.5, 4.0, length=100)","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"True banana density values:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"true_density = [banana_density([x1, x2]) for x2 in x₂, x1 in x₁]\nnothing # hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Learned density via pullback through the transport map. Note that \"pullback\" computes the density of the mapped samples in the standard normal space:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"learned_density = [pullback(C, [x1, x2]) for x2 in x₂, x1 in x₁]\nnothing # hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Create contour plots for comparison:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"p3 = contour(x₁, x₂, true_density,\n    title=\"True Banana Density\",\n    xlabel=\"x₁\", ylabel=\"x₂\",\n    colormap=:viridis, levels=10)\n\np4 = contour(x₁, x₂, learned_density,\n    title=\"Learned Density (Pullback)\",\n    xlabel=\"x₁\", ylabel=\"x₂\",\n    colormap=:viridis, levels=10)\n\nplot(p3, p4, layout=(1, 2), size=(800, 400))\nsavefig(\"density-comparison.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"(Image: Density Comparison)","category":"page"},{"location":"Examples/banana_mapfromsamples/#Combined-Visualization","page":"Banana: Map from Samples","title":"Combined Visualization","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Finally, let's create a combined plot showing both the original samples and the density contours:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"scatter(target_samples[:, 1], target_samples[:, 2],\n    label=\"Original Samples\", alpha=0.3, color=1,\n    xlabel=\"x₁\", ylabel=\"x₂\",\n    title=\"Banana Distribution: Samples and Learned Density\")\n\ncontour!(x₁, x₂, learned_density ./ maximum(learned_density),\n    levels=5, colormap=:viridis, alpha=0.8,\n    label=\"Learned Density Contours\")\n\nxlims!(-3, 3)\nylims!(-2.5, 4.0)\nsavefig(\"combined-result.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"(Image: Combined Result)","category":"page"},{"location":"Examples/banana_mapfromsamples/#Quality-Assessment","page":"Banana: Map from Samples","title":"Quality Assessment","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"We can assess the quality of our sample-based approximation by comparing statistics of the original and mapped samples:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"println(\"Sample Statistics Comparison:\")\nprintln(\"Original samples - Mean: \", Distributions.mean(target_samples, dims=1))\nprintln(\"Original samples - Std:  \", Distributions.std(target_samples, dims=1))\nprintln(\"Mapped samples - Mean:   \", Distributions.mean(mapped_banana_samples, dims=1))\nprintln(\"Mapped samples - Std:    \", Distributions.std(mapped_banana_samples, dims=1))","category":"page"},{"location":"Examples/banana_mapfromsamples/#Interpretation","page":"Banana: Map from Samples","title":"Interpretation","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"The sample-based approach learns the transport map by fitting to the empirical distribution of the samples. This method is particularly useful when:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"The target density is unknown or expensive to evaluate\nOnly sample data is available from experiments or simulations\nThe distribution is complex and difficult to express analytically","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"The quality of the approximation depends on:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"The number and quality of the original samples\nThe polynomial degree of the transport map\nThe optimization algorithm and convergence criteria","category":"page"},{"location":"Examples/banana_mapfromsamples/#Further-Experiments","page":"Banana: Map from Samples","title":"Further Experiments","text":"","category":"section"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"You can experiment with:","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"Different polynomial degrees for more complex distributions\nDifferent rectifier functions (Softplus(), ShiftedELU())\nMore sophisticated MCMC sampling strategies\nCross-validation techniques to assess generalization\nDifferent sample sizes to study convergence behavior","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"","category":"page"},{"location":"Examples/banana_mapfromsamples/","page":"Banana: Map from Samples","title":"Banana: Map from Samples","text":"This page was generated using Literate.jl.","category":"page"},{"location":"Manuals/map_parameterization/#Choosing-a-Map-Parameterization","page":"Map Parameterization","title":"Choosing a Map Parameterization","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"A crucial aspect of constructing transport maps is the choice of map parameterization. In addition to the choice of the univariate basis functions, the construction of the multi-index set that defines the multi-dimensional polynomial expansion for each component can significantly influence the performance of the map.","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"The k-th component of a triangular transport map is defined as T^k mathbbR^k to mathbbR [3]","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"T^k(z_1 z_2dotsz_k boldsymbola) = f(z_1 z_2dotsz_k-10boldsymbola) + int_0^z_k g(partial_k f(z_1 z_2dotsz_k-1xiboldsymbola))  mathrmd xi","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Here, g is a monotone increasing function that ensures the monotonicity of the map, which is a necessary property for transport maps. A common choice for g is the softplus function, defined as g(x) = log(1 + e^x).","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Further, f is a multivariate polynomial function parameterized by coefficients boldsymbola. The polynomial function f can be expressed as a linear combination of multivariate basis functions:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"f(z_1 z_2dotsz_k boldsymbola) = sum_alpha in mathcalA_k a_alpha Psi_alpha(z_1 z_2dotsz_k)","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Here, Psi_alpha(z_1 z_2dotsz_k) = prod_i=1^k psi_alpha_i(z_i) are multivariate basis functions constructed from univariate basis functions psi_alpha_i(z_i), and mathcalA_k is the multi-index set that determines which polynomial terms are included in the expansion.","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"By selecting an appropriate multi-index set mathcalA_k, the structure of the map itself can be tailored to the problem at hand. This includes the ability to create sparse maps, which can be particularly beneficial in high-dimensional settings or when the underlying relationships are known to be simpler. This feature is similar to the concept of sparse polynomial chaos expansions used in (forward) uncertainty propagation [11].","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"In TransportMaps.jl, three types of map structures outlined in [1] are implemented:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Total Order Map: Includes all terms up to a specified total degree p for d dimensions. In order to maintain the triangular structure, the k-th component of the map only depends on the first k variables. Thus, the multivariate basis for the k-th component is constructed from the first k univariate bases. The multi-index set alpha satisfies:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"mathcalA_k^TO = boldsymbolalpha boldsymbolalpha_1  leq p  wedge  alpha_i = 0  forall  i  k","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"No-Mixed Terms Map: Excludes mixed terms, retaining only pure terms for each variable. The multi-index set alpha satisfies:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"mathcalA_k^NM = boldsymbolalpha boldsymbolalpha_1  leq p  wedge  alpha_i alpha_j = 0   forall  i neq j  wedge  alpha_i = 0   forall  i  k","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Diagonal Map: Includes only diagonal terms, where each variable is independent of the others. The multi-index set alpha for the k-th component satisfies:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"mathcalA_k^D = boldsymbolalpha boldsymbolalpha_1  leq p  wedge  alpha_i = 0  forall  i neq k","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"For an better overview, the multi-index sets for each map type will be visualized later.","category":"page"},{"location":"Manuals/map_parameterization/#Constructing-Maps-with-Different-Parameterizations","page":"Map Parameterization","title":"Constructing Maps with Different Parameterizations","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"We will now demonstrate how to construct and compare the three types of map parameterizations using TransportMaps.jl. We start by importing the necessary packages:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"using TransportMaps\nusing Plots\nusing Distributions","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Then we define the three types of (sparse) maps. We consider a two-dimensional map with polynomial degree p=3, softplus as the rectifier function, and Hermite polynomials as the univariate basis functions.","category":"page"},{"location":"Manuals/map_parameterization/#Total-Order-Map","page":"Map Parameterization","title":"Total Order Map","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"M_to = PolynomialMap(2, 3, :normal, Softplus(), HermiteBasis())\n# alternative: PolynomialMap(2, 3, :normal, Softplus(), HermiteBasis(), :total)","category":"page"},{"location":"Manuals/map_parameterization/#No-mixed-terms-Map","page":"Map Parameterization","title":"No-mixed-terms Map","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"We can use the NoMixedMap constructor for this map type:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"M_nm = NoMixedMap(2, 3, :normal, Softplus(), HermiteBasis())\n# alternative: PolynomialMap(2, 3, :normal, Softplus(), HermiteBasis(), :no_mixed)","category":"page"},{"location":"Manuals/map_parameterization/#Diagonal-Map","page":"Map Parameterization","title":"Diagonal Map","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"For the diagonal map, we can use the DiagonalMap constructor:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"M_d = DiagonalMap(2, 3, :normal, Softplus(), HermiteBasis())\n# alternative: PolynomialMap(2, 3, :normal, Softplus(), HermiteBasis(), :diagonal)","category":"page"},{"location":"Manuals/map_parameterization/#Visualizing-Multi-Index-Sets","page":"Map Parameterization","title":"Visualizing Multi-Index Sets","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"The multi-index set determines the terms included in the polynomial expansion. We extract the multi-index sets of the second component of each map for visualization:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Extract the multi-index sets of the second component of each map for visualization:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"ind_to = getmultiindexsets(M_to.components[2])\nind_nm = getmultiindexsets(M_nm.components[2])\nind_d = getmultiindexsets(M_d.components[2])\nnothing #hide","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Finally, we plot the multi-index sets for each map type. This allows us to reproduce the comparison of multi-index sets as shown in Figure 1 in [1]:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"scatter(ind_to[:, 1], ind_to[:, 2], ms=20, label=\"Total Order\",)\nscatter!(ind_nm[:, 1], ind_nm[:, 2], ms=12, label=\"No Mixed\")\nscatter!(ind_d[:, 1], ind_d[:, 2], ms=6, label=\"Diagonal\")\nscatter!(xlim=(-0.5, 3.5), ylim=(-0.5, 3.5), aspect_ratio=1, legend=:topright,\n    xlabel=\"Multi-index α₁\", ylabel=\"Multi-index α₂\",\n    title=\"Multi-index Set of Map Component M²\")\nsavefig(\"multi_indices.svg\"); nothing # hide","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"(Image: Multi Index Sets)","category":"page"},{"location":"Manuals/map_parameterization/#Example:-Comparing-Map-Parameterizations","page":"Map Parameterization","title":"Example: Comparing Map Parameterizations","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"We optimize the coefficients of each map to match a cubic target density. The target density is defined as:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"p(x) = phi(x_1) cdot phi(x_2 - x_1^3 - x_1^2)","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"where phi is the standard normal PDF.","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Define the cubic target density and visualize it:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"cubic_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^3 - x[1]^2)\n\nx₁ = range(-3, 3, length=1000)\nx₂ = range(-10, 20, length=1000)\n\ntrue_density = [cubic_density([x1, x2]) for x2 in x₂, x1 in x₁]\ncontour(x₁, x₂, true_density;\n    label=\"x₁\", ylabel=\"x₂\", colormap=:viridis, levels=10)","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"We create the MapTargetDensity and quadrature weights for optimization:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"target = MapTargetDensity(cubic_density, :auto_diff)\nquadrature = SparseSmolyakWeights(3, 2)\nnothing #hide","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Generate samples in the standard normal space boldsymbolZ for the variance diagnostic:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"samples_z = randn(1000, 2)\nnothing #hide","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Now, we optimize each map type, compute the variance diagnostic and visualize the mapped samples.","category":"page"},{"location":"Manuals/map_parameterization/#Total-Order-Map-2","page":"Map Parameterization","title":"Total Order Map","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"We start with the total order map:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"optimize!(M_to, target, quadrature)\n\nmapped_samples = evaluate(M_to, samples_z)\nvar_diag = variance_diagnostic(M_to, target, samples_z)\nprintln(\"Variance Diagnostic: \", var_diag)\n\nscatter(mapped_samples[:, 1], mapped_samples[:, 2],\n    ms=4, label=nothing, c=1, title=\"Total Order\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\nsavefig(\"total_order.svg\"); nothing # hide","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"(Image: Total Order)","category":"page"},{"location":"Manuals/map_parameterization/#No-Mixed-Terms-Map","page":"Map Parameterization","title":"No Mixed Terms Map","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Next, we optimize the no-mixed-terms map:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"optimize!(M_nm, target, quadrature)\n\nmapped_samples_no_mixed = evaluate(M_nm, samples_z)\nvar_diag_no_mixed = variance_diagnostic(M_nm, target, samples_z)\nprintln(\"Variance Diagnostic: \", var_diag_no_mixed)\n\nscatter(mapped_samples_no_mixed[:, 1], mapped_samples_no_mixed[:, 2],\n    ms=4, label=nothing, c=2, title=\"No Mixed\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\nsavefig(\"no_mixed.svg\"); nothing # hide","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"(Image: No Mixed)","category":"page"},{"location":"Manuals/map_parameterization/#Diagonal-Map-2","page":"Map Parameterization","title":"Diagonal Map","text":"","category":"section"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"Finally, we optimize the diagonal map:","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"optimize!(M_d, target, quadrature)\n\nmapped_samples_diagonal = evaluate(M_d, samples_z)\nvar_diag_diagonal = variance_diagnostic(M_d, target, samples_z)\nprintln(\"Variance Diagnostic: \", var_diag_diagonal)\n\nscatter(mapped_samples_diagonal[:, 1], mapped_samples_diagonal[:, 2],\n    ms=4, label=nothing, c=3, title=\"Diagonal\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\nsavefig(\"diagonal.svg\"); nothing # hide","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"(Image: Diagonal)","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"We observe that the total order and no-mixed-terms maps achieve similar variance diagnostics, while the diagonal map performs significantly worse due to its inability to capture dependencies between variables.","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"note: Adaptive Map Construction\nThe choice of map parameterization can significantly impact the performance of transport maps. In practice, one might start with a simpler map structure, such as the diagonal or no-mixed-terms map, and then adaptively enrich the map based on the observed performance, as discussed in [3]. This adaptive approach allows for a balance between computational efficiency and approximation accuracy. For more information see the Adaptive Transport Maps manual and [3].","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"","category":"page"},{"location":"Manuals/map_parameterization/","page":"Map Parameterization","title":"Map Parameterization","text":"This page was generated using Literate.jl.","category":"page"},{"location":"api/#API-Reference","page":"API","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"This page provides a comprehensive reference for all exported functions and types in TransportMaps.jl.","category":"page"},{"location":"api/#Transport-Maps","page":"API","title":"Transport Maps","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"This will be added later.","category":"page"},{"location":"Examples/banana_mapfromdensity/#Banana:-Map-from-Density","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"This example demonstrates how to use TransportMaps.jl to approximate a \"banana\" distribution using polynomial transport maps.","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"The banana distribution is a common test case in transport map literature [1], defined as a standard normal in the first dimension and a normal distribution centered at x_1^2 in the second dimension. This example showcases the effectiveness of triangular transport maps for capturing nonlinear dependencies [3].","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"We start with the necessary packages:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"using TransportMaps\nusing Distributions\nusing Plots","category":"page"},{"location":"Examples/banana_mapfromdensity/#Creating-the-Transport-Map","page":"Banana: Map from Density","title":"Creating the Transport Map","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"We start by creating a 2-dimensional polynomial transport map with degree 2 and a Softplus rectifier function.","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"M = PolynomialMap(2, 2, Normal(), Softplus())","category":"page"},{"location":"Examples/banana_mapfromdensity/#Setting-up-Quadrature","page":"Banana: Map from Density","title":"Setting up Quadrature","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"For optimization, we need to specify quadrature weights. Here we use a sparse Smolyak grid with level 2:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"quadrature = SparseSmolyakWeights(2, 2)","category":"page"},{"location":"Examples/banana_mapfromdensity/#Defining-the-Target-Density","page":"Banana: Map from Density","title":"Defining the Target Density","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"The banana distribution has the density:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"p(x) = phi(x_1) cdot phi(x_2 - x_1^2)","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"where phi is the standard normal PDF.","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"target_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)\nnothing #hide","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"Create a MapTargetDensity object for optimization","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"target = MapTargetDensity(target_density, :auto_diff)","category":"page"},{"location":"Examples/banana_mapfromdensity/#Optimizing-the-Map","page":"Banana: Map from Density","title":"Optimizing the Map","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"Now we optimize the map coefficients to approximate the target density:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"res = optimize!(M, target, quadrature)\nprintln(\"Optimization result: \", res)","category":"page"},{"location":"Examples/banana_mapfromdensity/#Testing-the-Map","page":"Banana: Map from Density","title":"Testing the Map","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"Let's generate some samples from the standard normal distribution and map them through our optimized transport map:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"samples_z = randn(1000, 2)","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"Map the samples through our transport map:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"mapped_samples = evaluate(M, samples_z)","category":"page"},{"location":"Examples/banana_mapfromdensity/#Visualizing-Results","page":"Banana: Map from Density","title":"Visualizing Results","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"Let's create a scatter plot of the mapped samples to see how well our transport map approximates the banana distribution:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"scatter(mapped_samples[:, 1], mapped_samples[:, 2],\n    label=\"Mapped Samples\", alpha=0.5, color=2,\n    title=\"Transport Map Approximation of Banana Distribution\",\n    xlabel=\"x₁\", ylabel=\"x₂\")\nsavefig(\"samples-banana.svg\"); nothing # hide","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"(Image: Banana Samples)","category":"page"},{"location":"Examples/banana_mapfromdensity/#Quality-Assessment","page":"Banana: Map from Density","title":"Quality Assessment","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"We can assess the quality of our approximation using the variance diagnostic:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"var_diag = variance_diagnostic(M, target, samples_z)\nprintln(\"Variance Diagnostic: \", var_diag)","category":"page"},{"location":"Examples/banana_mapfromdensity/#Interpretation","page":"Banana: Map from Density","title":"Interpretation","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"The variance diagnostic provides a measure of how well the transport map approximates the target distribution. Lower values indicate better approximation.","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"The scatter plot should show the characteristic \"banana\" shape, with samples curved according to the relationship x_2 propto x_1^2.","category":"page"},{"location":"Examples/banana_mapfromdensity/#Further-Experiments","page":"Banana: Map from Density","title":"Further Experiments","text":"","category":"section"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"You can experiment with:","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"Different polynomial degrees (see [3] for monotone map theory)\nDifferent rectifier functions (IdentityRectifier(), ShiftedELU())\nDifferent quadrature methods (MonteCarloWeights, LatinHypercubeWeights, GaussHermiteWeights)\nMore quadrature points for higher accuracy","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"","category":"page"},{"location":"Examples/banana_mapfromdensity/","page":"Banana: Map from Density","title":"Banana: Map from Density","text":"This page was generated using Literate.jl.","category":"page"},{"location":"Manuals/adaptive_transport_map/#Adaptive-Transport-Maps","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"","category":"section"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"A key challenge in constructing transport maps is choosing the appropriate parameterization, specifically the multi-index set that defines which polynomial terms to include in the expansion. While fixed parameterizations like total order, no-mixed terms, or diagonal maps (see Choosing a Map Parameterization) can work well in many cases, they may not be optimal for all target distributions.","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"Adaptive transport maps address this limitation by automatically selecting the most relevant polynomial terms through a greedy enrichment strategy. This approach is particularly useful when:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"The structure of the target distribution is unknown a priori\nComputational resources are limited and a sparse representation is desired\nHigh-dimensional problems require careful selection of interaction terms","category":"page"},{"location":"Manuals/adaptive_transport_map/#Theory","page":"Adaptive Transport Maps","title":"Theory","text":"","category":"section"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"The adaptive transport map (ATM) algorithm was introduced by [3] and provides a principled approach to construct sparse, triangular transport maps by adaptively enriching the multi-index set based on gradient information.","category":"page"},{"location":"Manuals/adaptive_transport_map/#Greedy-Multi-Index-Selection","page":"Adaptive Transport Maps","title":"Greedy Multi-Index Selection","text":"","category":"section"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"Given a triangular transport map with components T^k mathbbR^k to mathbbR for k=1ldotsd, each component is parameterized by a polynomial expansion:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"T^k(z_1 ldots z_k boldsymbola) = f(z_1 ldots z_k-1 0 boldsymbola) + int_0^z_k gleft(partial_k f(z_1 ldots z_k-1 xi boldsymbola)right) dxi","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"where f is a multivariate polynomial:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"f(z_1 ldots z_k boldsymbola) = sum_alpha in Lambda_k a_alpha Psi_alpha(z_1 ldots z_k)","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"Here, Lambda_k is the multi-index set that determines which terms are included.","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"The ATM algorithm starts with a minimal multi-index set (typically containing only the constant term) and iteratively adds terms that maximize the improvement in the objective function. At each iteration t, given the current multi-index set Lambda_t, the algorithm:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"Identifies candidate terms from the reduced margin of Lambda_t:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"mathcalRM(Lambda_t) = alpha notin Lambda_t  alpha - e_i in Lambda_t text for all  i text with  alpha_i  0","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"where e_i is the i-th standard basis vector.","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"For each candidate alpha in mathcalRM(Lambda_t), evaluates the gradient of the objective with respect to the coefficient a_alpha (initialized to zero).\nSelects the candidate with the largest absolute gradient value:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"alpha^+ = argmax_alpha in mathcalRM(Lambda_t) leftfracpartial Jpartial a_alpharight","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"Updates the multi-index set: Lambda_t+1 = Lambda_t cup alpha^+ and optimizes all coefficients.","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"This greedy selection strategy ensures that at each iteration, the term most likely to improve the objective function is added, leading to sparse and efficient representations.","category":"page"},{"location":"Manuals/adaptive_transport_map/#Cross-Validation-for-Model-Selection","page":"Adaptive Transport Maps","title":"Cross-Validation for Model Selection","text":"","category":"section"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"A critical question when using adaptive transport maps is: how many terms should be included? Including too few terms may result in underfitting, while including too many can lead to overfitting.","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"To address this, the ATM implementation supports k-fold cross-validation. The algorithm:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"Splits the data into k folds\nFor each fold, trains the map on k-1 folds and validates on the remaining fold\nTracks both training and validation objectives at each iteration\nSelects the number of terms that minimizes the average validation objective across folds","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"This approach provides a data-driven way to balance model complexity and generalization performance.","category":"page"},{"location":"Manuals/adaptive_transport_map/#Usage-in-TransportMaps.jl","page":"Adaptive Transport Maps","title":"Usage in TransportMaps.jl","text":"","category":"section"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"The optimize_adaptive_transportmap function provides two main interfaces for constructing adaptive transport maps.","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"The simplest approach uses a fixed train-test split to monitor overfitting:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"M, histories = optimize_adaptive_transportmap(\n    samples,             # Matrix of samples (n_samples × d)\n    maxterms,            # Vector of maximum terms per component\n    lm,                  # Linear map for standardization (default: LinearMap(samples))\n    rectifier,           # Rectifier function (default: Softplus())\n    basis;               # Polynomial basis (default: LinearizedHermiteBasis())\n    optimizer = LBFGS(),\n    options = Optim.Options(),\n    test_fraction = 0.2  # Fraction of data for validation\n)","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"For automatic model selection, use k-fold cross-validation. This implementation is based on the original algorithm proposed in [3]:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"M, fold_histories, selected_terms, selected_folds = optimize_adaptive_transportmap(\n    samples,             # Matrix of samples (n_samples × d)\n    maxterms,            # Vector of maximum terms per component\n    k_folds,             # Number of folds for cross-validation\n    lm,                  # Linear map for standardization (default: LinearMap(samples))\n    rectifier,           # Rectifier function (default: Softplus())\n    basis;               # Polynomial basis (default: LinearizedHermiteBasis())\n    optimizer = LBFGS(),\n    options = Optim.Options()\n)","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"The k-fold version returns:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"M: The final composed transport map trained on all data with the selected number of terms\nfold_histories: Optimization histories for each component and fold\nselected_terms: Number of terms selected for each component based on cross-validation\nselected_folds: Which fold had the best performance for each component","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"example: Example\nThe usage is demonstrated in the example Banana: Adaptive Transport Map from Samples.","category":"page"},{"location":"Manuals/adaptive_transport_map/#References","page":"Adaptive Transport Maps","title":"References","text":"","category":"section"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"The implementation of adaptive transport maps is based on the work by Baptista et al.:","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"Baptista, R., Marzouk, Y., & Zahm, O. (2023). On the Representation and Learning of Monotone Triangular Transport Maps. Foundations of Computational Mathematics. https://doi.org/10.1007/s10208-023-09630-x\nMatlab implementation of the original ATM algorithm: https://github.com/baptistar/ATM","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"","category":"page"},{"location":"Manuals/adaptive_transport_map/","page":"Adaptive Transport Maps","title":"Adaptive Transport Maps","text":"This page was generated using Literate.jl.","category":"page"},{"location":"Manuals/getting_started/#Getting-Started-with-TransportMaps.jl","page":"Getting Started","title":"Getting Started with TransportMaps.jl","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"This guide will help you get started with TransportMaps.jl for constructing and using transport maps.","category":"page"},{"location":"Manuals/getting_started/#Basic-Concepts","page":"Getting Started","title":"Basic Concepts","text":"","category":"section"},{"location":"Manuals/getting_started/#What-is-a-Transport-Map?","page":"Getting Started","title":"What is a Transport Map?","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"A transport map T boldsymbolZ mapsto boldsymbolX is a mapping from reference space boldsymbolZ sim rho(boldsymbolz) to the target space boldsymbolX sim pi(boldsymbolx) [1]. Hence, the inverse map T^-1 boldsymbolX mapsto boldsymbolZ maps from the target to the reference space.","category":"page"},{"location":"Manuals/getting_started/#Triangular-Maps","page":"Getting Started","title":"Triangular Maps","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"TransportMaps.jl focuses on triangular transport maps [3], following the Knothe-Rosenblatt rearrangement [6]. This structure ensures that the map is invertible and the Jacobian determinant is easy to compute. A triangular map in n dimensions has the form:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"T(boldsymbolz) =\nleft(beginarrayc\nT_1(z_1) \nT_2(z_1 z_2) \nT_3(z_1 z_2 z_3) \nvdots \nT_n(z_1 z_2 dots z_n)\nendarray\nright)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"The inverse map T^-1 can be computed sequentially by inverting each component.","category":"page"},{"location":"Manuals/getting_started/#First-Example:-A-Simple-2D-Transport-Map","page":"Getting Started","title":"First Example: A Simple 2D Transport Map","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"using TransportMaps\nusing Distributions\nusing Random\nusing Plots\nusing LinearAlgebra","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Let's create a simple 2D transport map:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Set random seed for reproducibility","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Random.seed!(1234)\nnothing #hide","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Create a 2D polynomial map with degree 2","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"M = PolynomialMap(2, 2, Normal(), Softplus())","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"The map is initially identity (coefficients are zero)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"println(\"Initial coefficients: \", getcoefficients(M))","category":"page"},{"location":"Manuals/getting_started/#Defining-a-Target-Distribution","page":"Getting Started","title":"Defining a Target Distribution","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"For optimization, you need to define your target probability density. Let's start with a simple correlated Gaussian:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Example: Correlated Gaussian","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"function correlated_gaussian(x; ρ=0.8)\n    Σ = [1.0 ρ; ρ 1.0]\n    return pdf(MvNormal(zeros(2), Σ), x)\nend\nnothing #hide","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Create a MapTargetDensity object for optimization","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"target_density = MapTargetDensity(correlated_gaussian, :auto_diff)","category":"page"},{"location":"Manuals/getting_started/#Setting-up-Quadrature","page":"Getting Started","title":"Setting up Quadrature","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Choose an appropriate quadrature scheme for map optimization:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Gauss-Hermite quadrature (good for Gaussian-like targets)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"quadrature = GaussHermiteWeights(5, 2)  # 5 points per dimension, 2D\n# alternative options:\n# quadrature = MonteCarloWeights(1000, 2)  # 1000 samples, 2D\n# quadrature = LatinHypercubeWeights(1000, 2)\n# quadrature = SparseSmolyakWeights(3, 2)  # Level 3, 2D","category":"page"},{"location":"Manuals/getting_started/#Optimizing-the-Map","page":"Getting Started","title":"Optimizing the Map","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Fit the transport map to your target distribution:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"result = optimize!(M, target_density, quadrature)","category":"page"},{"location":"Manuals/getting_started/#Generating-Samples","page":"Getting Started","title":"Generating Samples","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Once optimized, use the map to generate samples:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Generate reference samples (standard Gaussian)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"n_samples = 1000\nreference_samples = randn(n_samples, 2)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Transform to target distribution","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"target_samples = evaluate(M, reference_samples)","category":"page"},{"location":"Manuals/getting_started/#Visualizing-Results","page":"Getting Started","title":"Visualizing Results","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Let's plot both the reference and target samples:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"p1 = scatter(reference_samples[:, 1], reference_samples[:, 2],\n    alpha=0.6, title=\"Reference Samples\",\n    xlabel=\"Z₁\", ylabel=\"Z₂\", legend=false, aspect_ratio=:equal)\n\np2 = scatter(target_samples[:, 1], target_samples[:, 2],\n    alpha=0.6, title=\"Target Samples\",\n    xlabel=\"X₁\", ylabel=\"X₂\", legend=false, aspect_ratio=:equal)\n\nplot(p1, p2, layout=(1, 2), size=(800, 400))\nsavefig(\"samples.svg\"); nothing # hide","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"(Image: Transport Map Samples)","category":"page"},{"location":"Manuals/getting_started/#Evaluating-Map-Quality","page":"Getting Started","title":"Evaluating Map Quality","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Check how well your map approximates the target:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Variance diagnostic (should be close to 1 for good maps)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"var_diag = variance_diagnostic(M, target_density, reference_samples)\nprintln(\"Variance diagnostic: \", var_diag)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"You can also check the Jacobian determinant","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"sample_point = [0.0, 0.0]\njac = jacobian(M, sample_point)\ndet_jac = det(jac)\nprintln(\"Jacobian determinant at origin: \", det_jac)","category":"page"},{"location":"Manuals/getting_started/#Working-with-Different-Rectifiers","page":"Getting Started","title":"Working with Different Rectifiers","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"The rectifier function affects the map's behavior. Let's compare different options:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"ShiftedELU rectifier","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"M_elu = PolynomialMap(2, 2, Normal(), ShiftedELU())\nresult_elu = optimize!(M_elu, target_density, quadrature)\nvar_diag_elu = variance_diagnostic(M_elu, target_density, reference_samples)\n\nprintln(\"Variance diagnostics:\")\nprintln(\"  Softplus: \", var_diag)\nprintln(\"  ShiftedELU: \", var_diag_elu)","category":"page"},{"location":"Manuals/getting_started/#More-Complex-Example:-Banana-Distribution","page":"Getting Started","title":"More Complex Example: Banana Distribution","text":"","category":"section"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Now let's try a more challenging target - the banana distribution:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Define banana density","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"banana_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)\ntarget_density_banana = MapTargetDensity(banana_density, :auto_diff)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Create a new map for this target and optimize:","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"M_banana = PolynomialMap(2, 2, Normal(), Softplus())\nresult_banana = optimize!(M_banana, target_density_banana, quadrature)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Generate samples","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"banana_samples = evaluate(M_banana, reference_samples)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Visualize the banana distribution","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"x1_grid = range(-3, 3, length=100)\nx2_grid = range(-3, 6, length=100)\nposterior_values = [banana_density([x₁, x₂]) for x₂ in x2_grid, x₁ in x1_grid]\n\nscatter(banana_samples[:, 1], banana_samples[:, 2],\n    alpha=0.6, title=\"Banana Distribution Samples\",\n    xlabel=\"X₁\", ylabel=\"X₂\", legend=false, aspect_ratio=:equal)\ncontour!(x1_grid, x2_grid, posterior_values, colormap=:viridis, label=\"Posterior Density\")\nsavefig(\"banana_samples.svg\"); nothing # hide","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"(Image: Banana Distribution Samples)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"Check quality","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"var_diag_banana = variance_diagnostic(M_banana, target_density_banana, reference_samples)\nprintln(\"Banana distribution variance diagnostic: \", var_diag_banana)","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"","category":"page"},{"location":"Manuals/getting_started/","page":"Getting Started","title":"Getting Started","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#TransportMaps.jl","page":"Home","title":"TransportMaps.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is an implementation of triangular transport maps in Julia based on the description in [1]. For a comprehensive introduction to transport maps, see [2]. The theoretical foundations for monotone triangular transport maps are detailed in [1], [3]. For practical applications in structural health monitoring and Bayesian inference, see [4].","category":"page"},{"location":"#What-are-Transport-Maps?","page":"Home","title":"What are Transport Maps?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Transport maps are smooth, invertible functions that can transform one probability distribution into another [1]. The mathematical foundation builds on the Rosenblatt transformation [5] and the Knothe-Rosenblatt rearrangement [6]. They are particularly useful for:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Sampling: Generate samples from complex distributions by transforming samples from simple distributions\nVariational inference: Approximate complex posterior distributions in Bayesian updating problems [4]\nDensity estimation: Learn the structure of complex probability distributions","category":"page"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Polynomial Maps: Triangular polynomial transport maps\nAdaptive Construction: Automatic selection of polynomial terms for efficient approximation\nMultiple Rectifiers: Support for different activation functions (Softplus, ShiftedELU, Identity)\nQuadrature Integration: Multiple quadrature schemes for map optimization\nOptimization: Built-in optimization routines for fitting maps to target densities\nMultithreaded evaluation for processing multiple points efficiently","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"https://github.com/lukasfritsch/TransportMaps.jl\")","category":"page"},{"location":"#Quick-Start-Example","page":"Home","title":"Quick Start Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here's a simple example showing how to construct a transport map for a \"banana\" distribution:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TransportMaps\nusing Distributions\n\n# Create a 2D polynomial map with degree 2 and Softplus rectifier\nM = PolynomialMap(2, 2, Normal(), Softplus())\n\n# Set up quadrature for optimization\nquadrature = GaussHermiteWeights(3, 2)\n\n# Define target density (banana distribution)\ntarget_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)\ntarget = MapTargetDensity(target_density, :auto_diff)\n\n# Optimize the map coefficients\nresult = optimize!(M, target, quadrature)\n\n# Generate samples by mapping standard Gaussian samples\nsamples_z = randn(1000, 2)\n# Matrix input automatically uses multithreading for better performance\nmapped_samples = evaluate(M, samples_z)\n\n# Evaluate map quality\nvariance_diag = variance_diagnostic(M, target, samples_z)","category":"page"},{"location":"#Package-Architecture","page":"Home","title":"Package Architecture","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package is organized around several key components:","category":"page"},{"location":"#Map-Components","page":"Home","title":"Map Components","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PolynomialMapComponent: Individual polynomial components of triangular maps\nHermiteBasis: Hermite polynomial basis functions\nMultivariateBasis: Multivariate polynomial basis construction","category":"page"},{"location":"#Transport-Maps","page":"Home","title":"Transport Maps","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PolynomialMap: Main triangular polynomial transport map implementation","category":"page"},{"location":"#Rectifier-Functions","page":"Home","title":"Rectifier Functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"IdentityRectifier: No transformation (linear)\nSoftplus: Smooth positive transformation\nShiftedELU: Exponential linear unit variant","category":"page"},{"location":"#Quadrature-and-Optimization","page":"Home","title":"Quadrature and Optimization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"GaussHermiteWeights: Gauss-Hermite quadrature points and weights\nMonteCarloWeights: Monte Carlo integration\nLatinHypercubeWeights: Latin hypercube sampling","category":"page"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"api.md\"]","category":"page"},{"location":"#Authors","page":"Home","title":"Authors","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Lukas Fritsch, Institute for Risk and Reliability, Leibniz University Hannover\nJan Grashorn, Chair for Engineering Materials and Building Preservation, Helmut-Schmidt-University Hamburg","category":"page"},{"location":"#Related-Implementation","page":"Home","title":"Related Implementation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ATM: Matlab code for adaptive transport maps [3]\nMParT: C++-based library for transport maps [7]\nTransportBasedInference.jl: Julia implementation of adaptive transport maps (ATM) and Kalman filters\nSequentialMeasureTransport.jl: Julia implementation of transport maps from sum-of-squares densities [8]\nTriangular-Transport-Toolbox: Python code for the triangular transport tutorial paper [2]","category":"page"},{"location":"Manuals/conditional_densities/#Conditional-Densities","page":"Conditional Densities and Samples","title":"Conditional Densities","text":"","category":"section"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"When constructing a transport map, the triangular structure of the Knothe-Rosenblatt rearrangement provides a systematic way to factorize the joint density into a product of conditional densities:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"pi(boldsymbolx) = pi(x_1) pi(x_2  x_1) pi(x_3  x_1 x_2) cdots pi(x_k  x_1 dots x_k-1)","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"In Refs. [1] and [2], the authors show that these conditional densities are obtained sequentially by inverting the map components after one another. We define a transport map as given in Getting Started with TransportMaps.jl.","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"The conditional density for x_k given x_1 dots x_k-1 is defined as:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"pi(x_k  x_1 dots x_k-1) = rho(z_k) left fracpartial T_k(z_k)partial z_k right^-1","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"where z_k is obtained by inverting the first k components of the map, i.e., z_k = T^k(x_1dotsx_k)^-1. Here, rho(z_k) represents the reference density, and T_k is the k-th component of the triangular map.","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Similarly, this allows us to sample from a conditional density pi(x_k  x_1 dots x_k-1) by first inverting the map to get z_k, and then evaluating x_k = T_k(z_1 dots z_k).","category":"page"},{"location":"Manuals/conditional_densities/#Setting-up-a-Transport-Map","page":"Conditional Densities and Samples","title":"Setting up a Transport Map","text":"","category":"section"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"For this example, we'll use the banana distribution as our target density, which is also used in Getting Started with TransportMaps.jl and Banana: Map from Density. The banana distribution is defined as a:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"pi(x_1 x_2) = phi(x_1) cdot phi(x_2 - x_1^2)","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"where phi is the standard normal PDF.","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"We load the packaged and define the banana density function and create a target density object:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"using TransportMaps\nusing Plots\nusing Distributions\n\nbanana_density(x) = pdf(Normal(), x[1]) * pdf(Normal(), x[2] - x[1]^2)\ntarget = MapTargetDensity(banana_density, :auto_diff)\nnothing #hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Define the map and quadrature; and optimize the map:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"M = PolynomialMap(2, 2, :normal, Softplus(), HermiteBasis())\nquadrature = GaussHermiteWeights(10, 2)\n\n# Optimize the map:\noptimize!(M, target, quadrature)\nnothing #hide","category":"page"},{"location":"Manuals/conditional_densities/#Conditional-Density-Evaluation","page":"Conditional Densities and Samples","title":"Conditional Density Evaluation","text":"","category":"section"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Now we can compute conditional densities. For simplicity, we look at a two-dimensional example, so we are interested in the conditional density pi(x_2  x_1 = 05).","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Define the conditioning variable and the variable to evaluate the conditional density:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"x₁ = 0.5\nx₂ = 0.8\ndensity = conditional_density(M, x₂, x₁)\nprintln(\"Conditional density π(x₂=$x₂ | x₁=$x₁) = $density\")","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Evaluate conditional density for multiple values:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"x₂_values = range(-3, 3, length=100)\ndensities = conditional_density(M, x₂_values, x₁)\nnothing #hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Plot the conditional density:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"plot(x₂_values, densities,\n    xlabel=\"x₂\", ylabel=\"π(x₂ | x₁=$x₁)\",\n    title=\"Conditional Density π(x₂ | x₁=$x₁)\",\n    linewidth=2, label=\"Conditional Density\")\nsavefig(\"conditional-density.svg\"); nothing # hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"(Image: Conditional Density)","category":"page"},{"location":"Manuals/conditional_densities/#Conditional-Sampling","page":"Conditional Densities and Samples","title":"Conditional Sampling","text":"","category":"section"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"We can also sample from the conditional density pi(x_2  x_1). First, we sample z_2 in the standard normal space and then evaluate the conditional map:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Single value sampling:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"z₂ = randn()\ncond_sample = conditional_sample(M, x₁, z₂)\nprintln(\"Conditional sample for z₂=$z₂: x₂=$cond_sample\")","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Multiple samples:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"z₂_values = randn(10_000)\ncond_samples = conditional_sample(M, x₁, z₂_values)\nnothing #hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Create a histogram of the conditional samples and overlay the analytical density:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"histogram(cond_samples, bins=50, normalize=:pdf, alpha=0.7,\n    label=\"Conditional Samples\", xlabel=\"x₂\", ylabel=\"Density\")\nplot!(x₂_values, densities, linewidth=2,\n    label=\"Conditional Density\")\nsavefig(\"conditional-sampling.svg\"); nothing # hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"(Image: Conditional Sampling)","category":"page"},{"location":"Manuals/conditional_densities/#Comparison-with-True-Conditional-Density","page":"Conditional Densities and Samples","title":"Comparison with True Conditional Density","text":"","category":"section"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Let's compare our transport map's conditional density with the true conditional density of the target distribution:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"True conditional density for the banana distribution:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"function true_banana_conditional_density(x₂, x₁)\n    # For the banana distribution π(x₁, x₂) = N(x₁; 0, 1) * N(x₂ - x₁²; 0, 1)\n    # The conditional density π(x₂|x₁) = N(x₂; x₁², 1)\n    # This is a normal distribution centered at x₁² with variance 1\n    μ_cond = x₁^2\n    σ_cond = 1.0\n    return pdf(Normal(μ_cond, σ_cond), x₂)\nend\nnothing #hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Compute true conditional densities:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"true_densities = [true_banana_conditional_density(x₂, x₁) for x₂ in x₂_values]\nnothing #hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Plot comparison:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"plot(x₂_values, densities, linewidth=2, label=\"TM Conditional\",\n    xlabel=\"x₂\", ylabel=\"π(x₂ | x₁=$x₁)\")\nplot!(x₂_values, true_densities, linewidth=2, linestyle=:dash,\n    label=\"True Conditional\")\ntitle!(\"Transport Map vs True Conditional Density\")\nsavefig(\"conditional-comparison.svg\"); nothing # hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"(Image: Conditional Comparison)","category":"page"},{"location":"Manuals/conditional_densities/#Multiple-Conditioning-Scenarios","page":"Conditional Densities and Samples","title":"Multiple Conditioning Scenarios","text":"","category":"section"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"Let's explore how the conditional density π(x₂ | x₁) changes as we vary x₁. This shows the nonlinear structure of the banana distribution:","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"x₁_values = [-0.6, 0.0, 1.0, 2.0]\n\np = plot(xlabel=\"x₂\", ylabel=\"π(x₂ | x₁)\",\n    title=\"Conditional Densities for Different x₁ Values\")\n\nfor (i, x₁_val) in enumerate(x₁_values)\n    densities_cond = conditional_density(M, x₂_values, x₁_val)\n    true_densities_cond = [true_banana_conditional_density(x₂, x₁_val) for x₂ in x₂_values]\n\n    plot!(p, x₂_values, densities_cond, linewidth=2,\n        label=\"TM: x₁=$x₁_val\", color=i)\n    plot!(p, x₂_values, true_densities_cond, linewidth=2, linestyle=:dash,\n        label=\"True: x₁=$x₁_val\", color=i)\nend\n\nplot!(p)\nsavefig(\"multiple-conditioning.svg\"); nothing # hide","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"(Image: Multiple Conditioning)","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"note: Note\nFor a more comprehensive example with real-world applications, see the Biochemical Oxygen Demand (BOD) Example.","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"","category":"page"},{"location":"Manuals/conditional_densities/","page":"Conditional Densities and Samples","title":"Conditional Densities and Samples","text":"This page was generated using Literate.jl.","category":"page"}]
}
